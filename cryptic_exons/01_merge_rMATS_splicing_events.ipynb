{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import itertools\n",
    "from itertools import izip\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from matplotlib_venn import venn2, venn3\n",
    "import pybedtools\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "from gscripts import GO\n",
    "from gscripts.rnaseq import splicing_map\n",
    "from gscripts.general import dataviz\n",
    "from gscripts.general import region_helpers\n",
    "\n",
    "img_dir = \"/home/gpratt/Dropbox/cryptic_splicing/data/human_data/splicing_maps\"\n",
    "heatmap_dir = \"/home/gpratt/Dropbox/cryptic_splicing/data/human_data/heatmaps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_id_to_name = region_helpers.gene_id_to_name(\"/projects/ps-yeolab/genomes/hg19/gencode/v19/gencode.v19.annotation.gtf.db\")\n",
    "gene_id_to_type = region_helpers.gene_id_to_type(\"/projects/ps-yeolab/genomes/hg19/gencode/v19/gencode.v19.annotation.gtf.db\")\n",
    "ensembl_id_to_name = {key.split(\".\")[0]: value for key, value in gene_id_to_name.items()}\n",
    "\n",
    "name_to_gene_id = {value: key for key, value in gene_id_to_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# master_processing_table = pd.read_table(\"/home/elvannostrand/data/ENCODE/project_stuff/ENCODE_MASTER_ID_LIST_20160301_AllDatasets.txt\", \n",
    "#                                         sep=\"\\t\",\n",
    "#                                         skiprows=1,\n",
    "#                                         names=[\"UID\", \"RBP_gID\", \"CellLine\", \"RBP_ENSG\", \"Antibody\", \"Lot\", \"CLIP_ENCODEAccID\", \"CLIP_Rep1ENC\", \"CLIP_Rep2ENC\", \"CLIP_InputENC\", \"RNASEQ_ENCODEAccID\",  \"Duplicate_RNASEQ_ENCODEAccID\", \"RNASEQ_ControlENC\", \"RNASEQ_KDRep1Bam\", \"RNASEQ_KDRep2Bam\", \"RNASEQ_ControlRep1Bam\", \"RNASEQ_ControlRep2Bam\", \"bar\"]\n",
    "# )\n",
    "\n",
    "master_processing_table = pd.read_table(\"/home/gpratt/Dropbox/encode_integration/20160408_ENCODE_MASTER_ID_LIST_AllDatasets.csv\", index_col=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rMATS(fn):\n",
    "    \"\"\"Given a file name parses it but also uses rMATS file structure to find cryptic events, infer them and returns the entire thing\"\"\"\n",
    "    df = pd.read_table(fn, index_col=0)\n",
    "    splice_type = os.path.basename(fn).split(\".\")[0]\n",
    "    dir_name = os.path.split(os.path.split(fn)[0])[0]\n",
    "    \n",
    "    normal =  pd.read_table(os.path.join(dir_name, \"ASEvents\", \"fromGTF.{}.txt\").format(splice_type), index_col=0)\n",
    "    cryptic = pd.read_table(os.path.join(dir_name, \"ASEvents\", \"fromGTF.novelEvents.{}.txt\").format(splice_type), index_col=0)\n",
    "    normal[\"is_cryptic\"] = normal.index.isin(cryptic.index)\n",
    "    normal = normal.drop(set(normal.columns).difference(set([\"is_cryptic\"])), axis=1)\n",
    "    df = df.join(normal)\n",
    "    return df\n",
    "\n",
    "#I have to resort to this iterator stragety to keep my memory footprint low\n",
    "#this takes all merged events and returns a group_id (count) and all the samples that have the event, along with the event itself (value)\n",
    "def events_dict_iter(grouped_events):\n",
    "    for count, (key, value) in enumerate(grouped_events.iteritems()):\n",
    "        yield count, value \n",
    "\n",
    "#This takes all the actual events and makes a maping of group_id to the original dataframe id\n",
    "def real_results_iter(grouped_events):\n",
    "    for key, value in events_dict_iter(grouped_events):\n",
    "        for item in value:\n",
    "            yield item, key\n",
    "            #real_results[item] = {\"group_id\": key}\n",
    "            \n",
    "def annotate_se_events(se_events):\n",
    "\n",
    "    #Group events by location\n",
    "    df = se_events.groupby([\"downstreamEE\", \"downstreamES\", \"upstreamEE\", \"upstreamES\", \"exonEnd\", \"exonStart_0base\"])\n",
    "\n",
    "    real_results_df = pd.DataFrame(pd.Series(dict(real_results_iter(df.groups)), name=\"group_id\"))\n",
    "    #Assign that value back to the full ist of event annotations\n",
    "    annotated_combined_events = pd.concat([se_events, real_results_df], axis=1)\n",
    "\n",
    "    return annotated_combined_events\n",
    "\n",
    "def get_rMATS_events(events_list):\n",
    "    #might want to eventually convert that into an events list\n",
    "    df = pd.DataFrame(pd.Series({os.path.basename(item): item for item in events_list}, name=\"events\"))\n",
    "    \n",
    "    df['SE'] = df.events.apply(lambda x: os.path.join(x, \"MATS_output\", \"SE.MATS.JunctionCountOnly.txt\"))\n",
    "    df['MXE'] = df.events.apply(lambda x: os.path.join(x, \"MATS_output\", \"MXE.MATS.JunctionCountOnly.txt\"))\n",
    "    df['A5SS'] = df.events.apply(lambda x: os.path.join(x, \"MATS_output\", \"A5SS.MATS.JunctionCountOnly.txt\"))\n",
    "    df['A3SS'] = df.events.apply(lambda x: os.path.join(x, \"MATS_output\", \"A3SS.MATS.JunctionCountOnly.txt\"))\n",
    "    df['RI'] = df.events.apply(lambda x: os.path.join(x, \"MATS_output\", \"RI.MATS.JunctionCountOnly.txt\"))\n",
    "    \n",
    "    print \"paths that didn't exist\", df[~df['SE'].apply(os.path.exists)].values\n",
    "    df = df[df['SE'].apply(os.path.exists)]\n",
    "    \n",
    "    se = pd.concat({key: parse_rMATS(value) for key, value in df.SE.iteritems()}, names=[\"condition\", \"event_id\"])\n",
    "    se = annotate_se_events(se)\n",
    "    \n",
    "    mxe = pd.concat({key: parse_rMATS(value) for key, value in df.MXE.iteritems()}, names=[\"condition\", \"event_id\"])\n",
    "    a5ss = pd.concat({key: parse_rMATS(value) for key, value in df.A5SS.iteritems()}, names=[\"condition\", \"event_id\"])\n",
    "    a3ss = pd.concat({key: parse_rMATS(value) for key, value in df.A3SS.iteritems()}, names=[\"condition\", \"event_id\"])\n",
    "    ri = pd.concat({key: parse_rMATS(value) for key, value in df.RI.iteritems()}, names=[\"condition\", \"event_id\"])\n",
    "    \n",
    "    all_events = pd.concat({\"SE\": se,\n",
    "                            \"MXE\": mxe,\n",
    "                            \"A5SS\": a5ss,\n",
    "                            \"A3SS\": a3ss,\n",
    "                            \"RI\": ri,\n",
    "                                  }, \n",
    "                                  names=[\"event_type\", \"condition\", \"event_id\"]\n",
    "                                 )\n",
    "    return all_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths that didn't exist [[ '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR060KRD_vs_ENCSR092WKG'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR060KRD_vs_ENCSR092WKG/MATS_output/SE.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR060KRD_vs_ENCSR092WKG/MATS_output/MXE.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR060KRD_vs_ENCSR092WKG/MATS_output/A5SS.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR060KRD_vs_ENCSR092WKG/MATS_output/A3SS.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR060KRD_vs_ENCSR092WKG/MATS_output/RI.MATS.JunctionCountOnly.txt']\n",
      " [ '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR362XMY_vs_ENCSR620PUP'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR362XMY_vs_ENCSR620PUP/MATS_output/SE.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR362XMY_vs_ENCSR620PUP/MATS_output/MXE.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR362XMY_vs_ENCSR620PUP/MATS_output/A5SS.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR362XMY_vs_ENCSR620PUP/MATS_output/A3SS.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR362XMY_vs_ENCSR620PUP/MATS_output/RI.MATS.JunctionCountOnly.txt']\n",
      " [ '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR602AWR_vs_ENCSR620PUP'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR602AWR_vs_ENCSR620PUP/MATS_output/SE.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR602AWR_vs_ENCSR620PUP/MATS_output/MXE.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR602AWR_vs_ENCSR620PUP/MATS_output/A5SS.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR602AWR_vs_ENCSR620PUP/MATS_output/A3SS.MATS.JunctionCountOnly.txt'\n",
      "  '/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/ENCSR602AWR_vs_ENCSR620PUP/MATS_output/RI.MATS.JunctionCountOnly.txt']]\n"
     ]
    }
   ],
   "source": [
    "#THIS NEEDS LARGE AMOUNTS OF MEMORY, RUN WITH ppn=4 minium, will have to optomize very soon for scaling\n",
    "encode_events = glob.glob(\"/home/gpratt/projects/encode/analysis/ad-hoc/rMATS/*\")\n",
    "stress_events = glob.glob(\"/home/gpratt/projects/cryptic_exons/analysis/ad-hoc/rMATS/*\")\n",
    "\n",
    "#filters out events that I won't use anyway, small speedups and hopefully will help with this next memory / scaling issue\n",
    "encode_events = [encode_event for encode_event in encode_events if os.path.basename(encode_event).split(\"_vs_\")[0] in master_processing_table.RNASEQ_ENCODEAccID.values]\n",
    "both_events = encode_events + stress_events\n",
    "\n",
    "all_events = get_rMATS_events(both_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbp_gid_dict = dict(zip(master_processing_table.RNASEQ_ENCODEAccID, master_processing_table.RBP_gID.values))\n",
    "cell_type_dict = dict(zip(master_processing_table.RNASEQ_ENCODEAccID, master_processing_table.CellLine.values))\n",
    "\n",
    "rbp_gid_dict[\"CA_HepG2\"] = 'CA'\n",
    "rbp_gid_dict[\"CA_K562\"] = 'CA'\n",
    "rbp_gid_dict[\"PQ1_HepG2\"] = 'PQ'\n",
    "rbp_gid_dict[\"PQ1_K562\"] = 'PQ'\n",
    "rbp_gid_dict[\"PQCA1_HepG2\"] = 'PQCA'\n",
    "rbp_gid_dict[\"PQCA1_K562\"] = 'PQCA'\n",
    "rbp_gid_dict[\"ars1_HepG2\"] = 'ars'\n",
    "rbp_gid_dict[\"ars1_K562\"] = 'ars'\n",
    "rbp_gid_dict[\"hs1_HepG2\"] = 'hs'\n",
    "rbp_gid_dict[\"hs1_K562\"] = 'hs'\n",
    "rbp_gid_dict[\"AV_Kin1ALS17_3_puro_S48_L007_R1_001\"]  = \"puro\"\n",
    "rbp_gid_dict[\"AV_ALS17_5_puro_1_S46_L007_R1_001\"] = \"puro\"\n",
    "rbp_gid_dict[\"AV_GY6_2_puro_1_S44_L007_R1_001\" ] = \"puro\"\n",
    "rbp_gid_dict[\"KK_MN_shFUS_7_S55_L008_R1_001\" ] = \"puro\"\n",
    "rbp_gid_dict[\"AV_47d_puro_1_S51_L008_R1_001\" ] = \"puro\"\n",
    "rbp_gid_dict[\"AV_CVB_puro_S49_L007_R1_001\" ] = \"puro\"\n",
    "rbp_gid_dict[\"KK_MN_shTAF_5_S54_L008_R1_001\" ] = \"puro\"\n",
    "rbp_gid_dict['KK_MN_shTDP_1_S52_L008_R1_001'] = \"puro\"\n",
    "\n",
    "cell_type_dict[\"CA_HepG2\"] = 'HepG2'\n",
    "cell_type_dict[\"CA_K562\"] = 'K562'\n",
    "cell_type_dict[\"PQ1_HepG2\"] = 'HepG2'\n",
    "cell_type_dict[\"PQ1_K562\"] = 'K562'\n",
    "cell_type_dict[\"PQCA1_HepG2\"] = 'HepG2'\n",
    "cell_type_dict[\"PQCA1_K562\"] = 'K562'\n",
    "cell_type_dict[\"ars1_HepG2\"] = 'HepG2'\n",
    "cell_type_dict[\"ars1_K562\"] = 'K562'\n",
    "cell_type_dict[\"hs1_HepG2\"] = 'HepG2'\n",
    "cell_type_dict[\"hs1_K562\"] = 'K562'\n",
    "cell_type_dict[\"AV_Kin1ALS17_3_puro_S48_L007_R1_001\"]  = \"MN\"\n",
    "cell_type_dict[\"AV_ALS17_5_puro_1_S46_L007_R1_001\"] = \"MN\"\n",
    "cell_type_dict[\"AV_GY6_2_puro_1_S44_L007_R1_001\" ] = \"MN\"\n",
    "cell_type_dict[\"KK_MN_shFUS_7_S55_L008_R1_001\" ] = \"MN\"\n",
    "cell_type_dict[\"AV_47d_puro_1_S51_L008_R1_001\" ] = \"MN\"\n",
    "cell_type_dict[\"AV_CVB_puro_S49_L007_R1_001\" ] = \"MN\"\n",
    "cell_type_dict[\"KK_MN_shTAF_5_S54_L008_R1_001\" ] = \"MN\"\n",
    "cell_type_dict['KK_MN_shTDP_1_S52_L008_R1_001'] = \"MN\"\n",
    "\n",
    "\n",
    "all_events['RNASEQ_ENCODEAccID'] = [condition.split(\"_vs_\")[0] for condition in all_events.index.get_level_values(\"condition\")]\n",
    "all_events['rbp'] = all_events.RNASEQ_ENCODEAccID.apply(lambda x: rbp_gid_dict[x])\n",
    "all_events['cell_type'] = all_events.RNASEQ_ENCODEAccID.apply(lambda x: cell_type_dict[x])\n",
    "all_events['both'] = all_events['rbp'] + \"_\" + all_events['cell_type']\n",
    "\n",
    "all_events.index = pd.MultiIndex.from_tuples([list(index) + [rbp, cell_type, both] for index, rbp, cell_type, both in izip(all_events.index, all_events.rbp, all_events.cell_type, all_events.both)], \n",
    "                                                         names=[\"event_type\", \"condition\", \"event_id\", 'rbp', 'cell_type', \"both\"])\n",
    "\n",
    "all_events = all_events.swaplevel(\"event_id\", \"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_events.to_csv(\"/home/gpratt/projects/cryptic_exons/analysis/ipython_data/merged_cryptic_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "print \"foo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
