{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pybedtools\n",
    "import numpy as np\n",
    "from pybedtools import featurefuncs\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotated_exons = pybedtools.BedTool(\"/projects/ps-yeolab/genomes/hg19/gencode/v19/gencode.v19.annotation.exon.gtf\").sort().saveas()\n",
    "annotated_exons_bed = annotated_exons.each(featurefuncs.gff2bed).saveas()\n",
    "\n",
    "#annotated_exons = pybedtools.BedTool(\"/home/gpratt/clipper/clipper/data/regions/hg19_exons.bed\").sort().saveas()\n",
    "annotated_genes = pybedtools.BedTool(\"/home/gpratt/clipper/clipper/data/regions/hg19_genes.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sj_table(fn):\n",
    "    return pd.read_table(fn,\n",
    "                         header=None, \n",
    "                         names=['chrom', 'start', 'stop', 'strand', 'intron_motif', 'annotated', 'unique_reads', 'multi_reads', 'max_overhang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /home/gpratt/projects/cryptic_exons/analysis/ling_et_al_v1/SRR2002765_1.polyATrim.adapterTrim.rmRep.bamSJ.out.tab does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-507495d3be5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m results = pd.concat({\"ctrl\": read_sj_table(\"/home/gpratt/projects/cryptic_exons/analysis/ling_et_al_v1/SRR2002765_1.polyATrim.adapterTrim.rmRep.bamSJ.out.tab\"),\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \"kd\":  read_sj_table(\"/home/gpratt/projects/cryptic_exons/analysis/ling_et_al_v1/SRR2002766_1.polyATrim.adapterTrim.rmRep.bamSJ.out.tab\"),},\n\u001b[0;32m      3\u001b[0m                      names=['condition', 'sj'])\n",
      "\u001b[1;32m<ipython-input-8-83eb86960428>\u001b[0m in \u001b[0;36mread_sj_table\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m      2\u001b[0m     return pd.read_table(fn,\n\u001b[0;32m      3\u001b[0m                          \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                          names=['chrom', 'start', 'stop', 'strand', 'intron_motif', 'annotated', 'unique_reads', 'multi_reads', 'max_overhang'])\n\u001b[0m",
      "\u001b[1;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3229)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6042)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File /home/gpratt/projects/cryptic_exons/analysis/ling_et_al_v1/SRR2002765_1.polyATrim.adapterTrim.rmRep.bamSJ.out.tab does not exist"
     ]
    }
   ],
   "source": [
    "results = pd.concat({\"ctrl\": read_sj_table(\"/home/gpratt/projects/cryptic_exons/analysis/ling_et_al_v1/SRR2002765_1.polyATrim.adapterTrim.rmRep.bamSJ.out.tab\"),\n",
    "                     \"kd\":  read_sj_table(\"/home/gpratt/projects/cryptic_exons/analysis/ling_et_al_v1/SRR2002766_1.polyATrim.adapterTrim.rmRep.bamSJ.out.tab\"),},\n",
    "                     names=['condition', 'sj'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_pass =  pd.read_table(\"/home/gpratt/projects/cryptic_exons/analysis/ad-hoc/SRR2096921_1.polyATrim.adapterTrim.rmRep.bamSJ.out.tab\",\n",
    "                    header=None, names=['chrom', 'start', 'stop', 'strand', 'intron_motif', 'annotated', 'unique_reads',\n",
    "                                      'multi_reads', 'max_overhang']) }, names=['condition', 'sj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Identify all possible exons given constraints\n",
    "1. Exons are no more than max_exon_size away from each other \n",
    "2. They are on the same strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['total_reads'] = results.unique_reads + results.multi_reads \n",
    "ctrl_unfiltered = results.ix['kd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data filtering\n",
    "#Try to get a bit more confidence in the splice junctions\n",
    "ctrl = ctrl_unfiltered[ctrl_unfiltered.total_reads  >= 5]\n",
    "#explicily not looking for unique reads, I lose a bunch of real splice junctions that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call_exons(sj_df):\n",
    "    \n",
    "    sj_df_pos = sj_df[sj_df.strand == 1]\n",
    "    sj_df_neg = sj_df[sj_df.strand == 2]\n",
    "\n",
    "    exons = set([])\n",
    "    chroms = set(sj_df.chrom)\n",
    "    max_exon_size = 1000\n",
    "    for chrom in chroms:\n",
    "        #Positive Strand\n",
    "        sj_df_pos_chrom = sj_df_pos[sj_df_pos.chrom == chrom]\n",
    "\n",
    "        result = {}\n",
    "        for name, row in sj_df_pos_chrom.iterrows():\n",
    "            possible_junctions = row.stop - sj_df_pos_chrom.start\n",
    "            possible_junctions = possible_junctions[(0 > possible_junctions) & (np.abs(possible_junctions) < max_exon_size)]\n",
    "            result[name] = possible_junctions\n",
    "\n",
    "        for x, (exon_start, possible_ends) in enumerate(result.items()):\n",
    "            if len(possible_ends) == 0:\n",
    "                continue\n",
    "\n",
    "            possible_ends = possible_ends.apply(np.abs)\n",
    "            shortest_possible_exon = possible_ends.min()\n",
    "\n",
    "            key = possible_ends[possible_ends == shortest_possible_exon].index[0]\n",
    "            start = sj_df_pos_chrom.ix[exon_start].stop\n",
    "            stop = sj_df_pos_chrom.ix[key].start - 1\n",
    "            if stop < start:\n",
    "                continue\n",
    "            exons.add((chrom, start,stop, \"foo\", \"0\",\"+\"))\n",
    "\n",
    "        #Negative Strand\n",
    "        sj_df_neg_chrom = sj_df_neg[sj_df_neg.chrom == chrom]\n",
    "\n",
    "        result = {}\n",
    "        for start_id, row in sj_df_neg_chrom.iterrows():\n",
    "            possible_junctions = row.start - sj_df_neg_chrom.stop\n",
    "            possible_junctions = possible_junctions[(0 < possible_junctions) & (np.abs(possible_junctions) < max_exon_size)]\n",
    "            result[start_id] = possible_junctions\n",
    "\n",
    "        for x, (exon_start, possible_ends) in enumerate(result.items()):\n",
    "            if len(possible_ends) == 0:\n",
    "                continue\n",
    "\n",
    "            possible_ends = possible_ends.apply(np.abs)\n",
    "            shortest_possible_exon = possible_ends.min()\n",
    "\n",
    "            key = possible_ends[possible_ends == shortest_possible_exon].index[0]\n",
    "            stop = sj_df_neg_chrom.ix[exon_start].start - 1\n",
    "            start = sj_df_neg_chrom.ix[key].stop\n",
    "            if stop < start:\n",
    "                continue\n",
    "            exons.add((chrom, start,stop, \"foo\", \"0\",\"-\"))\n",
    "\n",
    "    exons = pybedtools.BedTool([pybedtools.create_interval_from_list(list(exon)) for exon in exons]).sort().saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only get exons in known genes\n",
    "gene_exons = exons.intersect(annotated_genes, s=True, f=1.0, u=True).saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_exons.saveas(\"/home/gpratt/Dropbox/cryptic_splicing/data/splice_juncions/SRR2002766_1.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(exons), len(gene_exons)\n",
    "#Doesn't remove too many exons, but enough to take care of some false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#only get cryptic exons that don't overlap known exons\n",
    "#this should really be called cryptic exons\n",
    "kd_unannotated_exons = gene_exons.intersect(annotated_exons, s=True, v=True).saveas()\n",
    "kd_possible_annotated_exons = gene_exons.intersect(annotated_exons, u=True, s=True).saveas()\n",
    "\n",
    "kd_annotated_exons = kd_possible_annotated_exons.intersect(annotated_exons, s=True, u=True, f=1.0, r=True, sorted=True).saveas()\n",
    "kd_not_annotated_exons = kd_possible_annotated_exons.intersect(annotated_exons, s=True, v=True, f=1.0, r=True, sorted=True).saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kd_unannotated_exons.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kd_possible_annotated_exons.filter(lambda x: x.start == 242608196 ).saveas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Total number of exons, annotated and detected and unannotated and detected using my method.  \n",
    "len(annotated_exons), len(kd_possible_annotated_exons), len(kd_annotated_exons), len(kd_not_annotated_exons), len(kd_unannotated_exons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kd_not_annotated_exons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly fixed negative strand exon idenitifcation bug, but there is a subtle one still there, could actually just be a splicing error, should keep digging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Number of exons on chr 1 on positive strand\n",
    "len(annotated_exons.filter(lambda x: x.chrom == \"chr1\" and x.strand == \"+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like I might have a high false negative rate.  Let me filter out false positives a bit more and I'll figure out what I'm missing.\n",
    "\n",
    "Notes on Progress:\n",
    "1. Taking next splice junction isn't a bad strat, identifies 6365 / ??? expressed exons\n",
    "2. Identified False positives from junction spanning reads spanning two genes (fix by intersect bed making sure the exon is within a gene\n",
    "3. Identified False positives where one or two reads were leading to stuff that didn't quite look like exons.  Filter via hurestrics?  \n",
    "\n",
    "I need a way to assess my false positive and negative rate.  Read bowtie paper for this?  Figure out how many annotated exons are expressed vs how many I identify?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Odd things:\n",
    "This should have been filtered: \n",
    "\n",
    "1. Filter splice sites in genes without exons.  Need to dig into gencode tags for this one.  Might just create a list of all the RPs and remove them, I think they are the main culprate for now.\n",
    "* chr1\t353809\t353865\n",
    "* chr1\t355353\t355386\n",
    " \n",
    "2. Filer odd short jumps.  Can do this by only taking half annotated splice junctions.  \n",
    "\n",
    "3. looks wrong, don't have a good patterns\n",
    "\n",
    "chr1\t2324708\t2324794\tfoo\t0\t+ --double splicing event, might want to handle this eventually\n",
    "chr1\t46466630\t46466651 -- looks real just real short, possibly noise\n",
    "chr1\t100474843\t100474879 -- looks really short, just ugly\n",
    "chr1\t144048708\t144048769 -- really short\n",
    "chr1\t156165803\t156165964 -- major mis-splicing\n",
    "chr1\t196644579\t196644659 -- doesn't look super real, not enough reads spanning splice junctions\n",
    "chr1\t179013907\t179013976 -- multiple 5' splice sites, what should I do about this?\n",
    "chr1\t203803064\t203803230 -- doesn't look super real, come back to this\n",
    "chr1\t203803064\t203803230 -- doesn't look super real, come back to this\n",
    "chr1\t225898204\t225898270 -- looks real, but not really in an annotated, gene, splice sites don't reconstruct well\n",
    "chr1\t225898204\t225898270 -- looks real, but not really in an annotated, gene, splice sites don't reconstruct well\n",
    "chr1\t100474843\t100474879 -- lots of noise, shouldn't keep.  Need to figure out how to remove\n",
    " \n",
    " \n",
    "chr1\t109438938\t109439053 -- bound by TDP43\n",
    "chr1\t154214175\t154214273 -- slightly bound by TDP-43\n",
    " chr1\t213299108\t213299186 -- bound nicely by TDP-43\n",
    "\n",
    "#Random Thoughts\n",
    "Argn has some crazy splicing patterns\n",
    "1. chr1\t980267\t980367\tfoo\t0\t+\n",
    "2. chr1\t980271\t980367\tfoo\t0\t+\n",
    "3. chr1\t980355\t980367\tfoo\t0\t+\n",
    "\n",
    "#Possible Next options.\n",
    "1. Try to figure out if I've got false negatives\n",
    "1. Keep filtering\n",
    "3. Add in neagative strand + rest of the chromosomes.  \n",
    "4. Think ahead even more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Assessing False Negatives\n",
    "General Stragety will be to look at featurecounts counts, see what things are covered (and have splice junctions) that I should know about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_exons = pd.read_table(\"/home/gpratt/projects/cryptic_exons/analysis/ling_et_al_v1/hg19_counts.txt\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expressed_exons = all_exons[all_exons['SRR2002766_1.polyATrim.adapterTrim.rmRep.bam'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expressed_exons_chr1 = expressed_exons[(expressed_exons.Chr == \"chr1\") & (expressed_exons.Strand == \"+\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_exons_chr1 = all_exons[(all_exons.Chr == \"chr1\") & (all_exons.Strand == \"+\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Number of exons on chr1 and the expressed exons on chr1\n",
    "print len(all_exons_chr1), len(expressed_exons_chr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get the exons I didn't detect with my algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expressed_exons_chr1_bed = []\n",
    "for name, row in expressed_exons_chr1.iterrows():\n",
    "    expressed_exons_chr1_bed.append(pybedtools.create_interval_from_list([row.Chr, \n",
    "                                          row.Start, \n",
    "                                          row.End, \n",
    "                                          row.Geneid, \n",
    "                                          row['SRR2002766_1.polyATrim.adapterTrim.rmRep.bam'], \n",
    "                                          row.Strand]))\n",
    "expressed_exons_chr1_bed = pybedtools.BedTool(expressed_exons_chr1_bed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chr1\t321032\t321290\tENSG00000237094.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expressed_exons_chr1_bed.intersect(kd_annotated_exons, v=True).head(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like I'm not detecting a lot of the annotated exons because there aren't any reads that span splice junctions, or meet my cutoff for what a \"true\" splice junction looks like.  \n",
    "\n",
    "This is both good and bad.  Good in that I'm not going to over-call peaks.  Bad in that I could be missing a lot of cryptic sites because I'm taking a splice junctino centric view.  I still like this approach.  I'm going to try using the STAR two pass approach to try and recover a few more reads and have things pass my thresholds a bit better.  In the mean time I'll generalize my algorithm to all chromosomes / strands.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#How Many Novel Exons overlap with exons called by Ling et. al?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ling_et_al_exons = \"\"\"chr5:111602907-111602981\n",
    "chr5:648215-648338\n",
    "chr19:7169645-7169842\n",
    "chr5:153416928-153417015\n",
    "chr10:3141749-3142011\n",
    "chr11:8797739-8801798\n",
    "chr12:117226441-117226517\n",
    "chr12:117227839-117228527\n",
    "chr12:85689446-85689514\n",
    "chr1:980268-980367\n",
    "chr1:980272-980367\n",
    "chr2:242608197-242608400\n",
    "chr1:980268-980460\n",
    "chr1:980272-980460\n",
    "chr11:8801680-8801798\n",
    "chr3:9510260-9510300\n",
    "chr11:108368528-108368891\n",
    "chr19:9112157-9112234\n",
    "chr19:14560900-14561129\n",
    "chr14:24630911-24631099\n",
    "chr10:11968921-11971863\n",
    "chr1:109438939-109439053\n",
    "chr13:21374252-21374294\n",
    "chr7:102227839-102228081\n",
    "chr7:102128667-102128909\n",
    "chr15:72557611-72557753\n",
    "chr12:52631354-52631501\n",
    "chr2:3462025-3462286\n",
    "chr22:20110103-20110220\n",
    "chr4:89319549-89319596\n",
    "chr1:169337730-169337948\n",
    "chr11:58384466-58384527\n",
    "chr19:4492012-4492149\n",
    "chr10:30731500-30731565\n",
    "chr2:182775853-182775960\n",
    "chr5:64836755-64836979\n",
    "chr6:33626324-33626446\n",
    "chr2:143722222-143728961\n",
    "chr14:24634266-24634392\n",
    "chrX:107465095-107465143\n",
    "chr2:143728740-143728961\"\"\".replace(\":\", \" \").replace(\"-\", \" \")\n",
    "\n",
    "ling_et_al_exons = pybedtools.BedTool(ling_et_al_exons, from_string=True).saveas(\"ling_et_al_exons.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ling_et_al_exons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ling_et_al_exons.intersect(kd_unannotated_exons, u=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#of the ones that I miss, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ling_et_al_exons.intersect(kd_unannotated_exons, v=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ling_et_al_exons.intersect(kd_unannotated_exons, v=True).head(n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "chr19\t7169645\t7169842 -- no splice junction on the 5' end\n",
    "chr12\t117226441\t117226517 -- not quite enough splice junctions (maybe have some off by one bugs)\n",
    "chr12\t117227839\t117228527 -- no splice junctions on the 3' end\n",
    "chr12\t85689446\t85689514 -- not enough splice junctions on the 5' end\n",
    "chr2\t242608197\t242608400 -- possibly call slightly shorter exon, need to look into this, also might just not be eonugh reads (overlaps with previous exon there is TDP-43 binding)\n",
    "chr3\t9510260\t9510300 -- miss called, exon near but not overlapping, I think (but there is TDP-43 binding)\n",
    "chr11\t108368528\t108368891 -- not enough reads on the 3' end (but TDP-43 binding)\n",
    "chr19\t9112157\t9112234 --I shouldn't have missed this one, look into it (no gene?)\n",
    "chr19\t14560900\t14561129 --not real cryptic exon\n",
    "chr14\t24630911\t24631099 -- no 5' reads\n",
    "chr10\t11968921\t11971863 -- no spliced reads detected\n",
    "chr13\t21374252\t21374294 -- 5' extention event, I wouldn't have detected this\n",
    "chr7\t102227839\t102228081 -- extention event I think.  Wouldn't have detected this\n",
    "chr7\t102128667\t102128909 -- extention event I think.  Wouldn't have detected this\n",
    "chr15\t72557611\t72557753  -- extention event I think.  Wouldn't have detected this\n",
    "chr12\t52631354\t52631501  -- extention event I think.  Wouldn't have detected this\n",
    "chr2\t3462025\t3462286  -- no 5' reads (there is another exon near here, may have called that)\n",
    "chr22\t20110103\t20110220 -- known exon (with TDP-43 binding though)\n",
    "chr4\t89319549\t89319596 -- should have detected this, don't know why I didn't (overlaps with known exon)\n",
    "chr1\t169337730\t169337948 -- no 5' reads \n",
    "chr5\t64836755\t64836979 -- no 5' reads\n",
    "chr6\t33626324\t33626446 -- looks like an extention\n",
    "chr2\t143722222\t143728961 -- this looks just kind of fucked up\n",
    "chr14\t24634266\t24634392 -- overlaps with a known exon\n",
    "chr2\t143728740\t143728961 -- no 3' reads "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cryptic_splicing = glob.glob(\"/home/gpratt/projects/cryptic_exons/analysis/av_resequencing_v1/*rmRep*.tab\")\n",
    "splice_junction_predictions = pd.concat({os.path.basename(item).split(\".\")[0]: read_sj_table(item) for item in cryptic_splicing},\n",
    "                                        names=['condition', 'sj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splice_junction_predictions['total_reads'] = splice_junction_predictions.unique_reads + splice_junction_predictions.multi_reads \n",
    "splice_junction_predictions_filtered = splice_junction_predictions[splice_junction_predictions.total_reads  >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for name, df in splice_junction_predictions_filtered.groupby(level=\"condition\"):\n",
    "    print name\n",
    "    result[name] = call_exons(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
