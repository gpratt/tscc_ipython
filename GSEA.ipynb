{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_sets = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc2 = unstressed_protein_coding_pca.loadings.ix['pc_2'].sort_values(ascending=False)\n",
    "large_sets = mm10GO.GO[(mm10GO.GO['nGenes'] > 25) & (mm10GO.GO['nGenes'] < 500)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "in_set = {}\n",
    "for name, genes in large_sets['Ensembl Gene ID'].iteritems():\n",
    "    result[name] = pc2.copy()\n",
    "    in_set[name] = {gene_id: True for gene_id in genes}\n",
    "\n",
    "result = pd.DataFrame(result)\n",
    "in_set = pd.DataFrame(in_set)\n",
    "in_set = in_set.fillna(False)\n",
    "\n",
    "incomplete_in_set = in_set.T\n",
    "\n",
    "for gene in result.index.difference(in_set.index):\n",
    "    incomplete_in_set[gene] = False\n",
    "    \n",
    "in_set = incomplete_in_set[result.index].T\n",
    "\n",
    "#is_set = in_set.reindex(result.index, fill_value=False)\n",
    "\n",
    "hit_values = result.copy()\n",
    "miss_values = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hit_values[~in_set] = 0\n",
    "hit_values = np.abs(hit_values)\n",
    "miss_values[:] = 0\n",
    "miss_values[~in_set] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enrichment_score_vectorized(hit_values, miss_values):\n",
    "    normalized_hit_values = hit_values / hit_values.sum()\n",
    "    normalized_miss_values = miss_values / miss_values.sum()\n",
    "\n",
    "    enrichment_score = normalized_hit_values.cumsum() - normalized_miss_values.cumsum()\n",
    "    return enrichment_score\n",
    "\n",
    "def get_largest_score_vectorized(enrichment_score):\n",
    "    combined_scores = pd.concat({\"max_score\": enrichment_score.max(), \"min_score\": enrichment_score.min()}).unstack()\n",
    "    return combined_scores.apply(lambda x: x.max_score if np.abs(x.max_score) > np.abs(x.min_score) else x.min_score, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrichment_score = enrichment_score_vectorized(hit_values, miss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "largest_enrichment = get_largest_score_vectorized(enrichment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for x in range(100):\n",
    "    index = list(hit_values.index)\n",
    "    #np.random.shuffle(df.index.get_values())\n",
    "    random.shuffle(index)\n",
    "    shuffled_hit_values = hit_values.copy().ix[index]\n",
    "    shuffled_miss_values = miss_values.copy().ix[index]\n",
    "\n",
    "    shuffled_hit_values.reset_index()\n",
    "    shuffled_miss_values.reset_index()\n",
    "    results[x] = get_largest_score_vectorized(enrichment_score_vectorized(shuffled_hit_values, shuffled_miss_values))\n",
    "shuffled_results = pd.concat(results).unstack()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
