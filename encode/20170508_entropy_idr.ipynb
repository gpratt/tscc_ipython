{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pysam\n",
    "import gspread\n",
    "from IPython.core.display import HTML\n",
    "import numpy as np\n",
    "from oauth2client.client import SignedJwtAssertionCredentials\n",
    "import pandas as pd\n",
    "import pybedtools\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pybedtools\n",
    "from gscripts.general import region_helpers\n",
    "from gscripts.general import dataviz\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "img_dir =\"/home/gpratt/Dropbox/encode_integration/for_eric/idr_qc/\"\n",
    "\n",
    "from gscripts.encode import encode_helpers\n",
    "import functools\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(\"Progress: \")\n",
    "from gscripts import qtools\n",
    "RESET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "legend = None\n",
    "\n",
    "OUTSIDE_LEGEND_SAVEFIG_KWS = dict(bbox_extra_artists=(legend,),\n",
    "                                  bbox_inches='tight')\n",
    "from matplotlib import rc\n",
    "\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "rc('text', usetex=False)\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_norm_dir = \"/projects/ps-yeolab3/encode/analysis/Eric_Input_Norm/\"\n",
    "split_dir = \"/home/gpratt/projects/idr/analysis/idr_v2/\"\n",
    "out_dir = \"/home/gpratt/projects/encode/analysis/peak_reanalysis_v14/\"\n",
    "frip_out_dir = \"/home/gpratt/projects/encode/analysis/frip_calculations/\"\n",
    "downsample_path = \"/home/gpratt/projects/idr/analysis/downsample_v2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data = encode_helpers.get_merged_data()\n",
    "\n",
    "#Filter out anything sequenced after 16/7/18\n",
    "merged_data = merged_data[merged_data['Submitted Date'] < datetime.date(2016, 7, 18)]\n",
    "#Filter out anything not_qced\n",
    "merged_data = merged_data[merged_data.is_qced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Construct manifest to process data\n",
    "merged_data['genome'] = 'hg19'\n",
    "idr_manifest = merged_data.unstack()\n",
    "idr_manifest = idr_manifest.reset_index()\n",
    "idr_manifest = idr_manifest[[(\"CLIP\", \"rep1\"), (\"CLIP\", \"rep2\"),\n",
    "                             (\"input_norm\", \"rep1\"), (\"input_norm\", \"rep2\"), \n",
    "                             (\"INPUT\", \"rep1\"),\n",
    "                             (\"genome\", \"rep1\"),\n",
    "                             (\"uID\", \"\"), \n",
    "                             (\"submitted\", \"rep1\"),\n",
    "                             (\"peaks_submitable\", \"rep1\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em_peaks_dir = \"/home/gpratt/projects/idr/analysis/input_em_peaks\"\n",
    "idr_manifest[('em_norm', 'rep1')] = idr_manifest[('input_norm', 'rep1')].apply(lambda x: os.path.join(em_peaks_dir, \".\".join(os.path.basename(x).split(\".\")[:2]) + \".peaks.em.v3.bed\"))\n",
    "idr_manifest[('em_norm', 'rep2')] = idr_manifest[('input_norm', 'rep2')].apply(lambda x: os.path.join(em_peaks_dir, \".\".join(os.path.basename(x).split(\".\")[:2]) + \".peaks.em.v3.bed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_split_bed(fn, split_num):\n",
    "    fn = \".\".join(os.path.basename(fn).split(\".\")[:3])\n",
    "    fn = \"{}.{}.peaks.norm.compressed.l2Fixed.bed\".format(fn, split_num)\n",
    "    fn = os.path.join(split_dir, fn)\n",
    "    return fn\n",
    "\n",
    "split_01 = functools.partial(get_split_bed, split_num=\"01\")\n",
    "split_02 = functools.partial(get_split_bed, split_num=\"02\")\n",
    "\n",
    "def get_split_bam(fn, split_num):\n",
    "    fn = \".\".join(os.path.basename(fn).split(\".\")[:3])\n",
    "    fn = \"{}.{}.bam\".format(fn, split_num)\n",
    "    fn = os.path.join(split_dir, fn)\n",
    "    return fn\n",
    "\n",
    "split_bam_01 = functools.partial(get_split_bam, split_num=\"01\")\n",
    "split_bam_02 = functools.partial(get_split_bam, split_num=\"02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idr_manifest[('rep1', '01')] = idr_manifest[('CLIP', 'rep1')].apply(split_01)\n",
    "idr_manifest[('rep1', '02')] = idr_manifest[('CLIP', 'rep1')].apply(split_02)\n",
    "\n",
    "idr_manifest[('rep2', '01')] = idr_manifest[('CLIP', 'rep2')].apply(split_01)\n",
    "idr_manifest[('rep2', '02')] = idr_manifest[('CLIP', 'rep2')].apply(split_02)\n",
    "\n",
    "idr_manifest[('merged', '01')] = idr_manifest['uID'].apply(lambda x: os.path.join(split_dir, x + \".merged.01.peaks.norm.compressed.l2Fixed.bed\"))\n",
    "idr_manifest[('merged', '02')] = idr_manifest['uID'].apply(lambda x: os.path.join(split_dir, x + \".merged.02.peaks.norm.compressed.l2Fixed.bed\"))\n",
    "\n",
    "idr_manifest[('rep1', '01_bam')] = idr_manifest[('CLIP', 'rep1')].apply(split_bam_01)\n",
    "idr_manifest[('rep1', '02_bam')] = idr_manifest[('CLIP', 'rep1')].apply(split_bam_02)\n",
    "\n",
    "idr_manifest[('rep2', '01_bam')] = idr_manifest[('CLIP', 'rep2')].apply(split_bam_01)\n",
    "idr_manifest[('rep2', '02_bam')] = idr_manifest[('CLIP', 'rep2')].apply(split_bam_02)\n",
    "\n",
    "idr_manifest[('merged', '01_bam')] = idr_manifest['uID'].apply(lambda x: os.path.join(split_dir, x + \".merged.01.bam\"))\n",
    "idr_manifest[('merged', '02_bam')] = idr_manifest['uID'].apply(lambda x: os.path.join(split_dir, x + \".merged.02.bam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idr_manifest = idr_manifest[idr_manifest[('rep1', '01')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('rep1', '02')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('rep2', '01')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('rep2', '02')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('merged', '01')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('merged', '02')].apply(os.path.exists)]\n",
    "\n",
    "idr_manifest = idr_manifest[idr_manifest[('rep1', '01_bam')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('rep1', '02_bam')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('rep2', '01_bam')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('rep2', '02_bam')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('merged', '01_bam')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('merged', '02_bam')].apply(os.path.exists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idr_manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run \"Em\" on all the RBPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def run_em_input_norm(peak, ip_bam, input_bam):\n",
    "#     em_peak_dir = \"/home/gpratt/projects/idr/analysis/input_em_peaks\"\n",
    "#     bed = os.path.join(em_peak_dir, \".\".join(os.path.basename(peak).split(\".\")[:3]) + \".em.bed\")\n",
    "#     full = os.path.join(em_peak_dir, \".\".join(os.path.basename(peak).split(\".\")[:3]) + \".em.full\")\n",
    "\n",
    "#     return \"eclip_input_norm -p {peak} --ip_bam {ip_bam} --input_bam {input_bam} -o {out_bed} -f {out_full}\".format(peak=peak,\n",
    "#                                                                                                             ip_bam=ip_bam,\n",
    "#                                                                                                             input_bam=input_bam,\n",
    "#                                                                                                             out_bed=bed,\n",
    "#                                                                                                             out_full=full)\n",
    "\n",
    "# def row_based_em_input_norm(row, rep, split):\n",
    "#     peaks = row[rep, split]\n",
    "#     ip_bam = row[rep, split + \"_bam\"]\n",
    "#     input_bam = row['INPUT', 'rep1'] \n",
    "#     return run_em_input_norm(peaks, ip_bam, input_bam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rep1_01_norm = functools.partial(row_based_em_input_norm, rep=\"rep1\", split=\"01\")\n",
    "# rep1_02_norm = functools.partial(row_based_em_input_norm, rep=\"rep1\", split=\"02\")\n",
    "\n",
    "# rep2_01_norm = functools.partial(row_based_em_input_norm, rep=\"rep2\", split=\"01\")\n",
    "# rep2_02_norm = functools.partial(row_based_em_input_norm, rep=\"rep2\", split=\"02\")\n",
    "\n",
    "# merged_01_norm = functools.partial(row_based_em_input_norm, rep=\"merged\", split=\"01\")\n",
    "# merged_02_norm = functools.partial(row_based_em_input_norm, rep=\"merged\", split=\"02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# em_input_norm_cmds = np.concatenate([idr_manifest[~idr_manifest[('rep1', '01')].apply(em_peaks).apply(os.path.exists)].apply(rep1_01_norm, axis=1).values,\n",
    "#                                      idr_manifest[~idr_manifest[('rep1', '02')].apply(em_peaks).apply(os.path.exists)].apply(rep1_02_norm, axis=1).values,\n",
    "#                                      idr_manifest[~idr_manifest[('rep2', '01')].apply(em_peaks).apply(os.path.exists)].apply(rep2_01_norm, axis=1).values,\n",
    "#                                      idr_manifest[~idr_manifest[('rep2', '02')].apply(em_peaks).apply(os.path.exists)].apply(rep2_02_norm, axis=1).values,\n",
    "#                                      idr_manifest[~idr_manifest[('merged', '01')].apply(em_peaks).apply(os.path.exists)].apply(merged_01_norm, axis=1).values,\n",
    "#                                      idr_manifest[~idr_manifest[('merged', '02')].apply(em_peaks).apply(os.path.exists)].apply(merged_02_norm, axis=1).values,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(em_input_norm_cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# job_name = \"em_input_norm_idr\"\n",
    "# job = qtools.Submitter(commands=em_input_norm_cmds,\n",
    "#                  job_name=\"{}\".format(job_name),\n",
    "#                 sh_filename=\"/home/gpratt/projects/idr/scripts/{}.sh\".format(job_name),\n",
    "#                 array=True,\n",
    "#                 walltime=\"8:00:00\",\n",
    "#                 out_filename=\"/home/gpratt/projects/idr/scripts/{}.out\".format(job_name),\n",
    "#                 err_filename=\"/home/gpratt/projects/idr/scripts/{}.err\".format(job_name),\n",
    "#                 queue=\"home-yeo\")\n",
    "# job.job()\n",
    "\n",
    "# print \"/home/gpratt/projects/idr/scripts/{}.sh\".format(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the old entropy peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(row, total_ip_reads, total_input_reads):\n",
    "    p_ip = float(row.ip_reads) / total_ip_reads\n",
    "    p_input = float(row.input_reads) / total_input_reads\n",
    "    \n",
    "    return p_ip * np.log2(p_ip / p_input)\n",
    "\n",
    "def calculate_entropy_file(peaks, ip_bam, input_bam):\n",
    "    entropy_peak_dir = \"/home/gpratt/projects/idr/analysis/idr_v2_entropy_bed\"\n",
    "    full_fn = peaks + '.full'\n",
    "    peak_name, ext = os.path.splitext(peaks)\n",
    "    out_bed = os.path.join(entropy_peak_dir, os.path.basename(peak_name) + \".entropy.bed\")\n",
    "    \n",
    "    if os.path.exists(out_bed):\n",
    "        return out_bed\n",
    "    \n",
    "    ip_reads = pysam.Samfile(ip_bam).mapped\n",
    "    input_reads = pysam.Samfile(input_bam).mapped\n",
    "\n",
    "    read_counts = pd.read_table(full_fn, names=[\"chrom\", \"start\", \"stop\", \"full_name\", \n",
    "                                                  \"ip_reads\", \"input_reads\", \"p_val\",\n",
    "                                                  \"chiqc_score\", \"test\", \"enrichment\", \n",
    "                                                  \"log10_p_val\", \"log2_fold_change\"])\n",
    "\n",
    "    tool = functools.partial(calculate_entropy, total_ip_reads=ip_reads, total_input_reads=input_reads)\n",
    "    read_counts['entropy'] = read_counts.apply(tool, axis=1)\n",
    "    read_counts['strand'] = read_counts.full_name.apply(lambda x: x.split(\":\")[2])\n",
    "    read_counts = read_counts[['chrom', 'start', 'stop', 'log10_p_val', 'log2_fold_change', 'strand', 'entropy', 'entropy', 'entropy']]\n",
    "    read_counts.to_csv(out_bed, index=False, header=False, sep=\"\\t\")\n",
    "    return out_bed\n",
    "\n",
    "def row_based_calculate_entropy_file(row, rep, split):\n",
    "    peaks = row[rep, split]\n",
    "    peaks = \".\".join(peaks.split(\".\")[:-3]) + \".bed\"\n",
    "    \n",
    "    ip_bam = row[rep, split + \"_bam\"]\n",
    "    input_bam = row['INPUT', 'rep1'] \n",
    "    return calculate_entropy_file(peaks, ip_bam, input_bam)\n",
    "\n",
    "def row_based_calculate_entropy_real_file(row, rep, split):\n",
    "    peaks = row['input_norm', split]\n",
    "    peaks = \".\".join(peaks.split(\".\")[:2]) + \".peaks.l2inputnormnew.bed.full.compressed2.bed\"\n",
    "    \n",
    "    ip_bam = row[rep, split]\n",
    "    input_bam = row['INPUT', 'rep1'] \n",
    "    return calculate_entropy_file(peaks, ip_bam, input_bam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep1_01_norm = functools.partial(row_based_calculate_entropy_file, rep=\"rep1\", split=\"01\")\n",
    "rep1_02_norm = functools.partial(row_based_calculate_entropy_file, rep=\"rep1\", split=\"02\")\n",
    "\n",
    "rep2_01_norm = functools.partial(row_based_calculate_entropy_file, rep=\"rep2\", split=\"01\")\n",
    "rep2_02_norm = functools.partial(row_based_calculate_entropy_file, rep=\"rep2\", split=\"02\")\n",
    "\n",
    "merged_01_norm = functools.partial(row_based_calculate_entropy_file, rep=\"merged\", split=\"01\")\n",
    "merged_02_norm = functools.partial(row_based_calculate_entropy_file, rep=\"merged\", split=\"02\")\n",
    "\n",
    "rep1_norm = functools.partial(row_based_calculate_entropy_real_file, rep=\"CLIP\", split=\"rep1\")\n",
    "rep2_norm = functools.partial(row_based_calculate_entropy_real_file, rep=\"CLIP\", split=\"rep2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idr_manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "374 don't remember if we are analyzing using 4000 or regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "283it [00:00, 1790.53it/s]            \n",
      "283it [00:00, 1912.11it/s]            \n",
      "283it [00:00, 1850.34it/s]            \n",
      "283it [00:00, 1891.33it/s]            \n",
      "283it [00:00, 1918.48it/s]            \n",
      "283it [00:00, 1894.89it/s]            \n",
      "115it [00:00, 275.23it/s]             "
     ]
    },
    {
     "ename": "IOError",
     "evalue": "('File /projects/ps-yeolab3/encode/analysis/Eric_Input_Norm/374_01.basedon_374_01.peaks.l2inputnormnew.bed.full.compressed2.bed.full does not exist', u'occurred at index 96')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-07057e9a3d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'merged'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'01_entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_01_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'merged'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'02_entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_02_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'real'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'01_entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep1_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'real'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'02_entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep2_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/tqdm/_tqdm.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;31m# Apply the provided function (in *args and **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4040\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4042\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4043\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/tqdm/_tqdm.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;31m# Apply the provided function (in *args and **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-edbaaa1f6886>\u001b[0m in \u001b[0;36mrow_based_calculate_entropy_real_file\u001b[0;34m(row, rep, split)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mip_bam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0minput_bam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'INPUT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rep1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_entropy_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mip_bam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_bam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-edbaaa1f6886>\u001b[0m in \u001b[0;36mcalculate_entropy_file\u001b[0;34m(peaks, ip_bam, input_bam)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                   \u001b[0;34m\"ip_reads\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_reads\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p_val\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                   \u001b[0;34m\"chiqc_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"enrichment\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                   \"log10_p_val\", \"log2_fold_change\"])\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_ip_reads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mip_reads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_input_reads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_reads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: ('File /projects/ps-yeolab3/encode/analysis/Eric_Input_Norm/374_01.basedon_374_01.peaks.l2inputnormnew.bed.full.compressed2.bed.full does not exist', u'occurred at index 96')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "194it [00:20, 275.23it/s]"
     ]
    }
   ],
   "source": [
    "idr_manifest[('rep1', '01_entropy')] = idr_manifest.progress_apply(rep1_01_norm, axis=1)\n",
    "idr_manifest[('rep1', '02_entropy')] = idr_manifest.progress_apply(rep1_02_norm, axis=1)\n",
    "idr_manifest[('rep2', '01_entropy')] = idr_manifest.progress_apply(rep2_01_norm, axis=1)\n",
    "idr_manifest[('rep2', '02_entropy')] = idr_manifest.progress_apply(rep2_02_norm, axis=1)\n",
    "idr_manifest[('merged', '01_entropy')] = idr_manifest.progress_apply(merged_01_norm, axis=1)\n",
    "idr_manifest[('merged', '02_entropy')] = idr_manifest.progress_apply(merged_02_norm, axis=1)\n",
    "idr_manifest[('real', '01_entropy')] = idr_manifest.progress_apply(rep1_norm, axis=1)\n",
    "idr_manifest[('real', '02_entropy')] = idr_manifest.progress_apply(rep2_norm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idr_out_dir = \"/home/gpratt/projects/idr/analysis/idr_v3\"\n",
    "\n",
    "def idr(peak_1, peak_2, out_file):\n",
    "    return \"source activate py3 && idr  '--samples'  '{}'  '{}'  '--input-file-type' 'bed'  '--rank' '7'  '--peak-merge-method' 'max'  '--plot'  '-o' '{}' '--allow-negative-scores'\".format(peak_1, peak_2, out_file)\n",
    "\n",
    "def rep1_idr(row):\n",
    "    peak_1 = row['rep1', '01_entropy']\n",
    "    peak_2 = row['rep1', '02_entropy']\n",
    "    out_file = row.uID[0] + \".rep1.txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n",
    "\n",
    "def rep2_idr(row):\n",
    "    peak_1 = row['rep2', '01_entropy']\n",
    "    peak_2 = row['rep2', '02_entropy']\n",
    "    out_file = row.uID[0] + \".rep2.txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n",
    "\n",
    "def merged_idr(row):\n",
    "    peak_1 = row['merged', '01_entropy']\n",
    "    peak_2 = row['merged', '02_entropy']\n",
    "    out_file = row.uID[0] + \".combined.txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n",
    "\n",
    "def real_idr(row):\n",
    "    peak_1 = row['real', '01_entropy']\n",
    "    peak_2 = row['real', '02_entropy']\n",
    "    out_file = row.uID[0] + \".txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idr_cmds = np.concatenate([idr_manifest.apply(rep1_idr, axis=1).values,\n",
    "                                     idr_manifest.apply(rep2_idr, axis=1).values,\n",
    "                                     idr_manifest.apply(merged_idr, axis=1).values,\n",
    "                                    ])                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idr_cmds = idr_manifest.apply(real_idr, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gpratt/projects/idr/scripts/idr.sh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running 282 tasks as an array-job.\n"
     ]
    }
   ],
   "source": [
    "job_name = \"idr\"\n",
    "job = qtools.Submitter(commands=idr_cmds,\n",
    "                 job_name=\"{}\".format(job_name),\n",
    "                sh_filename=\"/home/gpratt/projects/idr/scripts/{}.sh\".format(job_name),\n",
    "                array=True,\n",
    "                walltime=\"8:00:00\",\n",
    "                out_filename=\"/home/gpratt/projects/idr/scripts/{}.out\".format(job_name),\n",
    "                err_filename=\"/home/gpratt/projects/idr/scripts/{}.err\".format(job_name),\n",
    "                queue=\"home-yeo\")\n",
    "job.job()\n",
    "\n",
    "print \"/home/gpratt/projects/idr/scripts/{}.sh\".format(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the rest of the entropy peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_peaks_dir = \"/home/gpratt/projects/idr/analysis/input_em_peaks\"\n",
    "\n",
    "def em_peaks(peak):\n",
    "    bed = os.path.join(em_peaks_dir, \".\".join(os.path.basename(peak).split(\".\")[:3]) + \".em.v3.bed\")\n",
    "    return bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File \"/home/gpratt/projects/idr/analysis/input_em_peaks/202_01_PTBP1.merged.r2.em.v3.bed\" does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-fca03da97465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'01_peaks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_peaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'02_peaks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'02'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_peaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'01_peaks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_peaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'02_peaks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midr_manifest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rep2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'02'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_peaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2235\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m         \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:63043)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-210-ec732ee1584a>\u001b[0m in \u001b[0;36madjust_entropy\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbedtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpybedtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBedTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mbedtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_entropy_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpratt/anaconda/lib/python2.7/site-packages/pybedtools-0.7.0-py2.7-linux-x86_64.egg/pybedtools/bedtool.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, from_string, remote)\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File \"%s\" does not exist'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_isbam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misBAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File \"/home/gpratt/projects/idr/analysis/input_em_peaks/202_01_PTBP1.merged.r2.em.v3.bed\" does not exist"
     ]
    }
   ],
   "source": [
    "idr_manifest[('rep1', '01_peaks')] = idr_manifest[('rep1', '01')].apply(em_peaks).apply(adjust_entropy)\n",
    "idr_manifest[('rep1', '02_peaks')] = idr_manifest[('rep1', '02')].apply(em_peaks).apply(adjust_entropy)\n",
    "\n",
    "idr_manifest[('rep2', '01_peaks')] = idr_manifest[('rep2', '01')].apply(em_peaks).apply(adjust_entropy)\n",
    "idr_manifest[('rep2', '02_peaks')] = idr_manifest[('rep2', '02')].apply(em_peaks).apply(adjust_entropy)\n",
    "\n",
    "idr_manifest[('merged', '01_peaks')] = idr_manifest[('merged', '01')].apply(em_peaks).apply(adjust_entropy)\n",
    "idr_manifest[('merged', '02_peaks')] = idr_manifest[('merged', '02')].apply(em_peaks).apply(adjust_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idr_out_dir = \"/home/gpratt/projects/idr/analysis/idr_v3\"\n",
    "\n",
    "def idr(peak_1, peak_2, out_file):\n",
    "    return \"source activate py3 && idr  '--samples'  '{}'  '{}'  '--input-file-type' 'bed'  '--rank' '7'  '--peak-merge-method' 'max'  '--plot'  '-o' '{}' '--allow-negative-scores'\".format(peak_1, peak_2, out_file)\n",
    "\n",
    "def rep1_idr(row):\n",
    "    peak_1 = row['rep1', '01_peaks']\n",
    "    peak_2 = row['rep1', '02_peaks']\n",
    "    out_file = row.uID[0] + \".rep1.txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n",
    "\n",
    "def rep2_idr(row):\n",
    "    peak_1 = row['rep2', '01_peaks']\n",
    "    peak_2 = row['rep2', '02_peaks']\n",
    "    out_file = row.uID[0] + \".rep2.txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n",
    "\n",
    "def merged_idr(row):\n",
    "    peak_1 = row['merged', '01_peaks']\n",
    "    peak_2 = row['merged', '02_peaks']\n",
    "    out_file = row.uID[0] + \".combined.txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n",
    "\n",
    "def real_idr(row):\n",
    "    peak_1 = row['em_norm', 'rep1_adjust']\n",
    "    peak_2 = row['em_norm', 'rep2_adjust']\n",
    "    out_file = row.uID[0] + \".txt\"\n",
    "    out_file = os.path.join(idr_out_dir, out_file)\n",
    "    return idr(peak_1, peak_2, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/home/elvannostrand/data/clip/CLIPseq_analysis/scripts/PIPELINE_EricVersion/compare_vs_input_peakbased_wrapper2_OneOrTwoRepVersion_PEbamfileversion_submit.pl i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_entropy_interval(interval):\n",
    "    interval[4] = interval[6]\n",
    "    interval[3] = interval[6]\n",
    "    interval.append(interval[6])\n",
    "    interval.append(interval[6])\n",
    "    return interval\n",
    "\n",
    "def adjust_entropy(fn):\n",
    "    out_name, ext = os.path.splitext(fn)\n",
    "    out_file = out_name + \".adjust\" + ext\n",
    "    if os.path.exists(out_file):\n",
    "        return out_file\n",
    "    bedtool = pybedtools.BedTool(fn)\n",
    "    bedtool.each(adjust_entropy_interval).saveas(out_file)\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idr_manifest = idr_manifest[idr_manifest[('em_norm', 'rep1')].apply(os.path.exists)]\n",
    "idr_manifest = idr_manifest[idr_manifest[('em_norm', 'rep2')].apply(os.path.exists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/282 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|      | 111/282 [00:00<00:00, 1101.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%| | 242/282 [00:00<00:00, 1151.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|| 282/282 [00:00<00:00, 1258.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/282 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|  | 214/282 [00:00<00:00, 2137.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|| 282/282 [00:00<00:00, 2109.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "idr_manifest[('em_norm', 'rep1_adjust')] = idr_manifest[('em_norm', 'rep1')].progress_apply(adjust_entropy)\n",
    "idr_manifest[('em_norm', 'rep2_adjust')] = idr_manifest[('em_norm', 'rep2')].progress_apply(adjust_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"source activate py3 && idr  '--samples'  '/home/gpratt/projects/idr/analysis/input_em_peaks/203_01.basedon_203_01.peaks.em.v3.adjust.bed'  '/home/gpratt/projects/idr/analysis/input_em_peaks/203_02.basedon_203_02.peaks.em.v3.adjust.bed'  '--input-file-type' 'bed'  '--rank' '7'  '--peak-merge-method' 'max'  '--plot'  '-o' '/home/gpratt/projects/idr/analysis/idr_v3/203.txt' '--allow-negative-scores'\""
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idr_manifest.apply(real_idr, axis=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
