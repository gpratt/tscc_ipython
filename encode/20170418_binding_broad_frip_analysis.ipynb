{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook came from the frip notebook, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transcriptomic binding qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, row in merged_data.iterrows():\n",
    "    path, ext = os.path.splitext(os.path.basename(row.CLIP_rep1))\n",
    "    rep1_metrics = path + \".in_genes.metrics\"\n",
    "\n",
    "    results.append(format_frip_analysis(row.CLIP_rep1, \"/home/gpratt/clipper/clipper/data/regions/hg19_genes.bed\", rep1_metrics))\n",
    "    \n",
    "    path, ext = os.path.splitext(os.path.basename(row.CLIP_rep2))\n",
    "    rep2_metrics = path + \".in_genes.metrics\"\n",
    "    \n",
    "    results.append(format_frip_analysis(row.CLIP_rep2, \"/home/gpratt/clipper/clipper/data/regions/hg19_genes.bed\", rep2_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_maker.make_script(results,\n",
    "                     \"/home/gpratt/projects/encode/scripts/genic_binding_v1\",\n",
    "                     \"/home/gpratt/projects/encode/analysis/genic_binding/\",\n",
    "                     walltime=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intronic vs exonic binders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, row in merged_data.iterrows():\n",
    "    path, ext = os.path.splitext(os.path.basename(row.CLIP_rep1))\n",
    "    rep1_metrics = path + \".in_genes.metrics\"\n",
    "\n",
    "    results.append(format_frip_analysis(row.CLIP_rep1, \"/home/gpratt/clipper/clipper/data/regions/hg19_exons.bed\", rep1_metrics))\n",
    "    \n",
    "    path, ext = os.path.splitext(os.path.basename(row.CLIP_rep2))\n",
    "    rep2_metrics = path + \".in_genes.metrics\"\n",
    "    \n",
    "    results.append(format_frip_analysis(row.CLIP_rep2, \"/home/gpratt/clipper/clipper/data/regions/hg19_exons.bed\", rep2_metrics))\n",
    "    \n",
    "    path, ext = os.path.splitext(os.path.basename(row.INPUT))\n",
    "    rep1_metrics = path + \".in_genes.metrics\"\n",
    "\n",
    "    results.append(format_frip_analysis(row.INPUT, \"/home/gpratt/clipper/clipper/data/regions/hg19_exons.bed\", rep1_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_maker.make_script(results,\n",
    "                     \"/home/gpratt/projects/encode/scripts/exon_binding_v1\",\n",
    "                     \"/home/gpratt/projects/encode/analysis/exon_binding/\",\n",
    "                     walltime=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define broad vs narrow binders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_merged_length(fn):\n",
    "    bedtool = pybedtools.BedTool(fn)\n",
    "    bedtool = bedtool.sort().merge(s=True, d=100)\n",
    "    return np.mean([len(interval) for interval in bedtool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data['rep1_lengths'] = merged_data['uID_01.basedon_uID_01.peaks.l2inputnormnew.bed.compressed.bed'].apply(get_mean_merged_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(merged_data['rep1_lengths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data[merged_data.RBP == \"TAF15\"].rep2_filtered_lineant[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data['rep2_lengths'] = merged_data['uID_02.basedon_uID_02.peaks.l2inputnormnew.bed.compressed.bed'].apply(get_mean_merged_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, row in merged_data.iterrows():\n",
    "\n",
    "    path, ext = os.path.splitext(os.path.basename(row.CLIP_rep2))\n",
    "    rep2_metrics = path + \".in_genes.metrics\"\n",
    "    \n",
    "    results.append(format_frip_analysis(row.CLIP_rep2, \"/home/gpratt/clipper/clipper/data/regions/hg19_genes.bed\", rep2_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data['rep1_neg_bw'] = merged_data.CLIP_rep1.apply(lambda x: os.path.splitext(x)[0] + \".norm.neg.bw\")\n",
    "merged_data['rep1_pos_bw'] = merged_data.CLIP_rep1.apply(lambda x: os.path.splitext(x)[0] + \".norm.pos.bw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbp_map = splicing_map.ReadDensity(merged_data['rep1_neg_bw'][1], merged_data['rep1_pos_bw'][1])\n",
    "peaks_of_interest = pybedtools.BedTool(merged_data['uID_01.basedon_uID_01.peaks.l2inputnormnew.bed.compressed.bed'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_bound_regions = foo.intersect(bar, u=True, s=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_coverage = bamtool.coverage(only_bound_regions, s=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_coverage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic idea, get regions that are already thought to be bound by peaks, look to see if reads in those regions are broadly distributed or narrowly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(only_bound_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for interval in only_bound_regions:\n",
    "    baz = rbp_map.values(interval.chrom, interval.start, interval.stop, interval.strand)\n",
    "    result.append(np.median(np.array(baz) / sum(baz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying just very basic coverage test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data[merged_data.RBP == \"HNRNPA2B1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hg19_genes = pybedtools.BedTool(\"/home/gpratt/clipper/clipper/data/regions/hg19_genes.bed\").sort().saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_expressed_gene_coverage(peaks, bam_file):\n",
    "    peaks_of_interest = pybedtools.BedTool(peaks).sort()\n",
    "    bamtool = pybedtools.BedTool(bam_file)\n",
    "    only_bound_regions = hg19_genes.intersect(peaks_of_interest, u=True, s=True, sorted=True)\n",
    "    gene_coverage = bamtool.coverage(only_bound_regions, s=True)\n",
    "    coverage = [float(interval[-1]) for interval in gene_coverage]\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taf15_coverage = get_expressed_gene_coverage(merged_data['uID_01.basedon_uID_01.peaks.l2inputnormnew.bed.compressed.bed'][250], \n",
    "                                             merged_data.CLIP_rep1[250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_coverage = {}\n",
    "for name, row in merged_data.iterrows():\n",
    "    gene_coverage[row.uID] = get_expressed_gene_coverage(row['uID_01.basedon_uID_01.peaks.l2inputnormnew.bed.compressed.bed'], \n",
    "                                row.CLIP_rep1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rows = 1 \n",
    "num_cols = 1 \n",
    "\n",
    "results = {}\n",
    "with dataviz.Figure(os.path.join(img_dir, \"foo.svg\"), figsize=(10 * num_cols, 10*num_rows)) as fig:\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    for name, row in gene_coverage.iteritems():\n",
    "        dataviz.plot_pdf(row, label=name, ax=ax)\n",
    "        pdf = np.concatenate(dataviz.pdf(row)[1])\n",
    "        results[merged_data[merged_data.uID == name].RBP.values[0]] = pdf\n",
    "        \n",
    "    ax.set_xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dir = \"/home/gpratt/Dropbox/Pratt,Gabriel/PapersInProgress/eCLIP_qc/working_figures/fig_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg = sns.clustermap(foo, col_cluster=False, figsize=(10,40))\n",
    "n = plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(img_dir, \"distributions.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the general coverage kind of works\n",
    "It fails for a bunch of narrow binders DGRC8 is one great example, RAVER1 is known to point source repress splicing, QKI should also be point source.  Switching to looking for enrichment over background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hg19_genes = pybedtools.BedTool(\"/home/gpratt/clipper/clipper/data/regions/hg19_genes.bed\")\n",
    "gene_lengths = {interval.name: len(interval) for interval in hg19_genes}\n",
    "gene_lengths = pd.Series(gene_lengths)\n",
    "hg19_windows = pybedtools.BedTool(\"/home/gpratt/projects/encode/analysis/ad-hoc/windowing_enrichment/hg19_windows.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fold_enrichment_coverage(ip_file, input_file, hg19_windows):\n",
    "    ip_bamtool = pybedtools.BedTool(ip_file)\n",
    "    input_bamtool = pybedtools.BedTool(input_file)\n",
    "    \n",
    "    ip_tool = ip_bamtool.coverage(hg19_windows, counts=True)\n",
    "    input_tool = input_bamtool.coverage(hg19_windows, counts=True)\n",
    "    \n",
    "    ip_mapped_reads = pysam.Samfile(ip_file).mapped\n",
    "    input_mapped_reads = pysam.Samfile(input_file).mapped\n",
    "\n",
    "    ip_mapped_reads /= 1000000.\n",
    "    input_mapped_reads /= 1000000.\n",
    "    \n",
    "    ip_df = ip_tool.to_dataframe()\n",
    "    input_df = input_tool.to_dataframe()\n",
    "    \n",
    "    ip_df.score = (ip_df.score + 1) / ip_mapped_reads\n",
    "    input_df.score = (input_df.score + 1) / input_mapped_reads\n",
    "    ip_df['region_length'] = ip_df.end - ip_df.start\n",
    "    ip_df['input_score'] = input_df.score\n",
    "    \n",
    "    ip_df['log2_fold_enrichment'] = np.log2(ip_df.score  / input_df.score)\n",
    "    return ip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_df_dgcr8 = fold_enrichment_coverage(\"/projects/ps-yeolab3/encode/analysis/encode_master/341_01_DGCR8.merged.r2.bam\",\n",
    "                         \"/projects/ps-yeolab3/encode/analysis/encode_master/341_INPUT_TCCGGAGA-CCTATCCT_L002_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.bam\",\n",
    "                            hg19_windows\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_df = ip_df_dgcr8[ip_df_dgcr8.log2_fold_enrichment > 4]\n",
    "covered_regions = filtered_df.groupby(\"name\").region_length.sum()\n",
    "sns.distplot((covered_regions / gene_lengths).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_df.region_length.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_df_rbfox2 = fold_enrichment_coverage(\"/projects/ps-yeolab3/encode/analysis/encode_v12/204_01_RBFOX2.merged.r2.bam\",\n",
    "                         \"/projects/ps-yeolab2/encode/analysis/encode_v12/RBFOX2-204-INPUT_S2_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.bam\",\n",
    "                            hg19_windows\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_df = ip_df_rbfox2[ip_df_rbfox2.log2_fold_enrichment > 4]\n",
    "covered_regions = filtered_df.groupby(\"name\").region_length.sum()\n",
    "sns.distplot((covered_regions / gene_lengths).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data[merged_data.RBP == \"TAF15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_coverage_enriched = {}\n",
    "for name, row in merged_data.iterrows():\n",
    "    ip_df = fold_enrichment_coverage(row.CLIP_rep1, row.INPUT, hg19_windows)\n",
    "    \n",
    "    filtered_df = ip_df[ip_df.log2_fold_enrichment > 4]\n",
    "    covered_regions = filtered_df.groupby(\"name\").region_length.sum()\n",
    "    gene_coverage_enriched[row.uID] = (covered_regions / gene_lengths).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = merged_data[merged_data.RBP == \"TAF15\"].ix[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_bamtool = pybedtools.BedTool(row.CLIP_rep1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_tool = ip_bamtool.coverage(hg19_windows, counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_tool.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_df = fold_enrichment_coverage(row.CLIP_rep1, row.INPUT, hg19_windows)\n",
    "filtered_df = ip_df[ip_df.log2_fold_enrichment > 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_df[ip_df.log2_fold_enrichment > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rows = 1 \n",
    "num_cols = 1 \n",
    "\n",
    "results = {}\n",
    "mean_results = {}\n",
    "with dataviz.Figure(os.path.join(img_dir, \"foo.svg\"), figsize=(10 * num_cols, 10*num_rows)) as fig:\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    for name, row in gene_coverage_enriched.iteritems():\n",
    "        if len(row) == 0:\n",
    "            continue\n",
    "            \n",
    "        dataviz.plot_pdf(row, label=name, ax=ax)\n",
    "        pdf = np.concatenate(dataviz.pdf(row)[1])\n",
    "        rbp_name = merged_data[merged_data.uID == name].RBP.values[0] + \"_\" + merged_data[merged_data.uID == name]['Cell line'].values[0]\n",
    "        results[rbp_name] = pdf\n",
    "        mean_results[rbp_name] = np.mean(row)\n",
    "        \n",
    "    ax.set_xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg = sns.clustermap(foo, col_cluster=False, figsize=(10,40))\n",
    "n = plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(img_dir, \"distributions.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_results = pd.Series(mean_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_results.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exonic vs intronic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict, Counter\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "from IPython.core.display import HTML, Image\n",
    "from matplotlib_venn import venn3\n",
    "import pandas as pd\n",
    "import pybedtools\n",
    "import pysam\n",
    "import gspread\n",
    "from gscripts.general import parsers\n",
    "from gscripts.general import dataviz\n",
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "%autoreload 2\n",
    "reload(parsers)\n",
    "reload(pybedtools)\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from oauth2client.client import SignedJwtAssertionCredentials\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "\n",
    "\n",
    "img_dir = \"/home/gpratt/Dropbox/encode_integration/qc_work/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_key = json.load(open(\"../public clip-588adbc137f3.json\"))\n",
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "\n",
    "credentials = SignedJwtAssertionCredentials(json_key['client_email'], json_key['private_key'], scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "sht1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1ZU2mQh54jentqvhR_oMnviLGWR8Nw_x338gULzKjNDI/edit#gid=0\")\n",
    "ws = sht1.worksheet(\"Sheet1\")\n",
    "list_of_lists = ws.get_all_values()\n",
    "manifest = pd.DataFrame(list_of_lists[1:], columns=list_of_lists[0])\n",
    "manifest['qc_id'] = manifest.apply(lambda x: \"{}_{}\".format(x.ENCODE_ID, x.RBP), axis=1)\n",
    "manifest.is_encode = manifest.is_encode == \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_metrics_v2(metrics_files, name):\n",
    "    filtered_frip_v12 = pd.concat({\"_\".join(os.path.basename(metrics_file).split(\"_\")[:2]) : pd.read_table(metrics_file) for metrics_file in metrics_files})\n",
    "\n",
    "    return encode_only_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_metrics_v2(glob.glob(\"/home/gpratt/projects/encode/analysis/exon_binding/*.metrics\"),\n",
    "               \"exonic_binding\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
