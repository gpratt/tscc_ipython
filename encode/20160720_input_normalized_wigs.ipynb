{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "print \"foo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pysam\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from gscripts.encode import encode_helpers\n",
    "from gscripts import qtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data = encode_helpers.get_merged_data()\n",
    "\n",
    "#For Peak Analysis we only want to analyze datasets that have been submitted\n",
    "merged_data = merged_data[merged_data.submitted]\n",
    "merged_data = merged_data[['CLIP', 'INPUT', 'input_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = \"/projects/ps-yeolab3/encode/analysis/normalized_wigs_v2\"\n",
    "\n",
    "def normalize_wig(ip_fn, input_fn):\n",
    "    ip_base = os.path.splitext(os.path.basename(ip_fn))[0]\n",
    "    input_base = os.path.splitext(os.path.basename(input_fn))[0]\n",
    "    print input_base \n",
    "    \n",
    "    ip_scaling_factor = 1000000. / pysam.Samfile(ip_fn).mapped\n",
    "    input_scapling_factor = 1000000. / pysam.Samfile(input_fn).mapped\n",
    "        \n",
    "    ip_bg = \"{}/{}.bg\".format(outdir, ip_base)\n",
    "    input_bg = \"{}/{}.bg\".format(outdir, input_base)\n",
    "    \n",
    "    ip_offset_wig = \"{}/{}.offset.wig\".format(outdir, ip_base)\n",
    "    input_offset_wig = \"{}/{}.offset.wig\".format(outdir, input_base)\n",
    "    \n",
    "    ip_offset_bw = \"{}/{}.offset.bw\".format(outdir, ip_base)\n",
    "    input_offset_bw = \"{}/{}.offset.bw\".format(outdir, input_base)\n",
    "    \n",
    "    normalized_wig = \"{}/{}.normalized.wig\".format(outdir, ip_base)\n",
    "    normalized_bw = \"{}/{}.normalized.bw\".format(outdir, ip_base)\n",
    "\n",
    "    normalized_bg = \"{}/{}.normalized.bg\".format(outdir, ip_base)\n",
    "    \n",
    "    !bedtools genomecov -ibam $ip_fn -bg -split -scale $ip_scaling_factor -g /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes > $ip_bg\n",
    "    !bedtools genomecov -ibam $input_fn -bg -scale $input_scapling_factor -split -g /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes > $input_bg\n",
    "    !/home/gpratt/software/WiggleTools/bin/wiggletools offset 1  $ip_bg > $ip_offset_wig\n",
    "    !/home/gpratt/software/WiggleTools/bin/wiggletools offset 1 $input_bg > $input_offset_wig\n",
    "\n",
    "    !wigToBigWig $ip_offset_wig /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes $ip_offset_bw\n",
    "    !wigToBigWig $input_offset_wig /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes $input_offset_bw\n",
    "\n",
    "    !/home/gpratt/software/WiggleTools/bin/wiggletools ratio $ip_offset_bw default 1 $input_offset_bw > $normalized_wig\n",
    "\n",
    "    !wigToBigWig $normalized_wig /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes $normalized_bw\n",
    "    !bigWigToBedGraph $normalized_bw $normalized_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clips = master_processing_table.dropna(subset=[\"CLIP_rep1\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTBP1-202-INPUT_S6_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2\n"
     ]
    }
   ],
   "source": [
    "for name, row in clips.iterrows():\n",
    "    ip_base = os.path.splitext(os.path.basename(row.CLIP_rep1))[0]\n",
    "    normalized_bw = \"{}/{}.normalized.bw\".format(outdir, ip_base)\n",
    "    if os.path.exists(normalized_bw):\n",
    "        print ip_base, \"exists\"\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        normalize_wig(row.CLIP_rep1, row.INPUT)\n",
    "        normalize_wig(row.CLIP_rep2, row.INPUT)\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Other approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bam = merged_data.CLIP[0]\n",
    "input_bam = merged_data.INPUT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bam = \"/home/gpratt/ad-hoc/chrM_test.bam\"\n",
    "input_bam = \"/home/gpratt/ad-hoc/chrM_input_test.bam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generated both dataframes\n",
    "bedtool = pybedtools.BedTool(bam)\n",
    "input_bedtool = pybedtools.BedTool(input_bam)\n",
    "\n",
    "df = bedtool.genome_coverage(dz=True, split=True, strand=\"+\").to_dataframe(names=['chrom', 'loc','coverage'])\n",
    "# neg_df = bedtool.genome_coverage(dz=True, split=True, strand=\"-\").to_dataframe(names=['chrom', 'loc',  'coverage'])\n",
    "\n",
    "input_df = input_bedtool.genome_coverage(dz=True, split=True, strand=\"+\").to_dataframe(names=['chrom', 'loc',  'coverage'])\n",
    "# input_neg_df = input_bedtool.genome_coverage(dz=True, split=True, strand=\"-\").to_dataframe(names=['chrom', 'loc', 'coverage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merged Dataframes\n",
    "merged_df = pd.merge(df, input_df, how='outer', \n",
    "                     left_on=['chrom', 'loc', ],\n",
    "                     right_on=['chrom', 'loc', ],\n",
    "                     suffixes=['_ip', '_input'],\n",
    "                    )\n",
    "\n",
    "# merged_neg_df = pd.merge(neg_df, input_neg_df, how='outer', \n",
    "#                          left_on=['chrom', 'loc',],\n",
    "#                          right_on=['chrom', 'loc',],\n",
    "#                          suffixes=['_ip', '_input'],\n",
    "#                         )\n",
    "\n",
    "#Add a pesudocount\n",
    "merged_df = merged_df.fillna(0)\n",
    "merged_df['coverage_ip'] += 1\n",
    "merged_df['coverage_input'] += 1\n",
    "\n",
    "# merged_neg_df = merged_neg_df.fillna(0)\n",
    "# merged_neg_df['coverage_ip'] += 1\n",
    "# merged_neg_df['coverage_input'] += 1\n",
    "\n",
    "#Compute total coverage across all regions\n",
    "total_ip = merged_df.coverage_ip.sum() #+ merged_neg_df.coverage_ip.sum()\n",
    "total_input = merged_df.coverage_input.sum() #+ merged_neg_df.coverage_input.sum()\n",
    "\n",
    "scale = 1000000\n",
    "\n",
    "#calculate probablity of IP and input (we scale it to avoid numerical percision issues)\n",
    "merged_df['p_ip'] = (merged_df.coverage_ip / total_ip) * scale\n",
    "merged_df['p_input'] = (merged_df.coverage_input / total_input) * scale\n",
    "\n",
    "# merged_neg_df['p_ip'] = (merged_neg_df.coverage_ip / total_ip) * scale\n",
    "# merged_neg_df['p_input'] = (merged_neg_df.coverage_input / total_input) * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df['scaled_entropy'] = (merged_df['p_ip']) * (np.log2(merged_df['p_ip'] ) - np.log2(merged_df['p_input']))\n",
    "# merged_neg_df['scaled_entropy'] = (merged_neg_df['p_ip']) * (np.log2(merged_neg_df['p_ip']) - np.log2(merged_neg_df['p_input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merged_neg_df.loc[merged_neg_df['scaled_entropy'] < 0, 'scaled_entropy'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df['start'] = (merged_df['loc'] - 1).astype(int)\n",
    "merged_df['stop'] = merged_df['loc'].astype(int)\n",
    "\n",
    "# merged_neg_df['start'] = merged_neg_df['loc'] - 1\n",
    "# merged_neg_df['stop'] = merged_neg_df['loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle_pos, fn_pos = tempfile.mkstemp()\n",
    "handle_neg, fn_neg = tempfile.mkstemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>loc</th>\n",
       "      <th>coverage_ip</th>\n",
       "      <th>coverage_input</th>\n",
       "      <th>p_ip</th>\n",
       "      <th>p_input</th>\n",
       "      <th>scaled_entropy</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>94842.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>94841</td>\n",
       "      <td>94842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>94843.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>94842</td>\n",
       "      <td>94843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>94844.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>94843</td>\n",
       "      <td>94844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>94845.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>94844</td>\n",
       "      <td>94845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>94846.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>94845</td>\n",
       "      <td>94846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom      loc  coverage_ip  coverage_input      p_ip   p_input  \\\n",
       "0  chr1  94842.0          2.0             1.0  0.004633  0.003584   \n",
       "1  chr1  94843.0          2.0             1.0  0.004633  0.003584   \n",
       "2  chr1  94844.0          2.0             1.0  0.004633  0.003584   \n",
       "3  chr1  94845.0          2.0             1.0  0.004633  0.003584   \n",
       "4  chr1  94846.0          2.0             1.0  0.004633  0.003584   \n",
       "\n",
       "   scaled_entropy  start   stop  \n",
       "0        0.001717  94841  94842  \n",
       "1        0.001717  94842  94843  \n",
       "2        0.001717  94843  94844  \n",
       "3        0.001717  94844  94845  \n",
       "4        0.001717  94845  94846  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.sort_values(['chrom', 'start', 'stop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = merged_df.sort_values(['chrom', 'start', 'stop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = foo.groupby(\"chrom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1 True\n",
      "chr10 True\n",
      "chr11 True\n",
      "chr12 True\n",
      "chr13 True\n",
      "chr14 True\n",
      "chr15 True\n",
      "chr16 True\n",
      "chr17 True\n",
      "chr18 True\n",
      "chr19 True\n",
      "chr2 True\n",
      "chr20 True\n",
      "chr21 True\n",
      "chr22 True\n",
      "chr3 True\n",
      "chr4 True\n",
      "chr5 True\n",
      "chr6 True\n",
      "chr7 True\n",
      "chr8 True\n",
      "chr9 True\n",
      "chrM True\n",
      "chrX True\n",
      "chrY True\n"
     ]
    }
   ],
   "source": [
    "for name, df in grp:\n",
    "    print name, all(df.start[:-1] < df.start[1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chrY_grp = grp.get_group(\"chrY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "[gpratt@tscc-1-32 scripts]$ bedGraphToBigWig ~/ad-hoc/foo.bg /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes /projects/ps-yeolab3/encode/analysis/entropy_bw/205_01_IGF2BP1.merged.r2.entropy.pos.bw\n",
    "Start (4294967295) after end (0) line 49382842 of /home/gpratt/ad-hoc/foo.bg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar = foo[foo.start == 4294967295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>loc</th>\n",
       "      <th>coverage_ip</th>\n",
       "      <th>coverage_input</th>\n",
       "      <th>p_ip</th>\n",
       "      <th>p_input</th>\n",
       "      <th>scaled_entropy</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chrom, loc, coverage_ip, coverage_input, p_ip, p_input, scaled_entropy, start, stop]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo[['chrom', 'start', 'stop', 'scaled_entropy']].to_csv(fn_pos, sep=\"\\t\", header=False, index=False, chunksize=40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151588138"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "151588138\n",
    "151588138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df[['chrom', 'start', 'stop', 'scaled_entropy']].to_csv(fn_pos, sep=\"\\t\", header=False, index=False, chunksize=20000)\n",
    "merged_neg_df[['chrom', 'start', 'stop', 'scaled_entropy']].to_csv(fn_neg, sep=\"\\t\", header=False, index=False, chunksize=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"foo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bw_pos = \"foo.pos.bw\"\n",
    "bw_neg = 'foo.neg.bw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wigToBigWig -keepAllChromosomes /state/partition1/gpratt/8681503.tscc-mgr.local/tmpTuEV9f /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes foo.pos.bw\n",
      "wigToBigWig -keepAllChromosomes /state/partition1/gpratt/8681503.tscc-mgr.local/tmpWu8Hv2 /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes foo.neg.bw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = \"bedGraphToBigWig {} /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes {}\".format(fn_pos, bw_pos)\n",
    "p1 = subprocess.Popen(cmd, shell=True)\n",
    "print cmd\n",
    "p1.wait()\n",
    "\n",
    "cmd = \"bedGraphToBigWig {} /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes {}\".format(fn_neg, bw_neg)\n",
    "p1 = subprocess.Popen(cmd, shell=True)\n",
    "print cmd\n",
    "p1.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = \"/projects/ps-yeolab3/encode/analysis/entropy_bw\"\n",
    "def run_entropy_bw(clip_fn, input_fn):\n",
    "    raw_name = os.path.splitext(os.path.basename(clip_fn))[0]\n",
    "    pos_name = os.path.join(out_dir, raw_name + \".entropy.pos.bw\")\n",
    "    neg_name = os.path.join(out_dir, raw_name + \".entropy.neg.bw\")\n",
    "\n",
    "    out_cmd = \"python ~/gscripts/gscripts/general/make_bigwig_entropy_files.py --ip_bam {} --input_bam {} --genome /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes --bw_pos {} --bw_neg {}\".format(clip_fn, input_fn, pos_name, neg_name)\n",
    "    return out_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, row in merged_data.iterrows():\n",
    "    clip_fn = row.CLIP\n",
    "    raw_name = os.path.splitext(os.path.basename(clip_fn))[0]\n",
    "    pos_name = os.path.join(out_dir, raw_name + \".entropy.pos.bw\")\n",
    "    neg_name = os.path.join(out_dir, raw_name + \".entropy.neg.bw\")\n",
    "\n",
    "    if not (os.path.exists(pos_name) and os.path.exists(neg_name)):\n",
    "        results.append(run_entropy_bw(row.CLIP, row.INPUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = merged_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, row in  merged_data.loc[['596', '460', '649', '654', '862']].iterrows():   \n",
    "    clip_fn = row.CLIP\n",
    "    raw_name = os.path.splitext(os.path.basename(clip_fn))[0]\n",
    "    pos_name = os.path.join(out_dir, raw_name + \".entropy.pos.bw\")\n",
    "    neg_name = os.path.join(out_dir, raw_name + \".entropy.neg.bw\")\n",
    "\n",
    "    if not (os.path.exists(pos_name) and os.path.exists(neg_name)):\n",
    "        print run_entropy_bw(row.CLIP, row.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_slices = 500\n",
    "full_process_list = []\n",
    "for x in range(num_slices):\n",
    "    cur_list = results[x::num_slices]\n",
    "    if len(cur_list) > 0:\n",
    "        full_process_list.append(\" && \".join(cur_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gpratt/projects/encode/scripts/entropy_input_norm.sh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running 167 tasks as an array-job.\n"
     ]
    }
   ],
   "source": [
    "job_name = \"entropy_input_norm\"\n",
    "job = qtools.Submitter(commands=full_process_list, \n",
    "                 job_name=\"{}\".format(job_name), \n",
    "                 sh_filename=\"/home/gpratt/projects/encode/scripts/{}.sh\".format(job_name),\n",
    "                array=True,\n",
    "                walltime=\"5:00:00\",\n",
    "                out_filename=\"/home/gpratt/projects/encode/scripts/{}.out\".format(job_name),\n",
    "                err_filename=\"/home/gpratt/projects/encode/scripts/{}.err\".format(job_name),\n",
    "                queue=\"condo\",\n",
    "                      ppn=16)\n",
    "job.job()\n",
    "\n",
    "print \"/home/gpratt/projects/encode/scripts/{}.sh\".format(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gscripts.general import make_bigwig_entropy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gscripts.general.make_bigwig_entropy_files' from '/home/gpratt/gscripts/gscripts/general/make_bigwig_entropy_files.pyc'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(make_bigwig_entropy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_stranded_coverage(bedtool):\n",
    "\n",
    "    pos_df = bedtool.genome_coverage(dz=True, split=True, strand=\"+\").to_dataframe(names=['chrom', 'loc', 'coverage'])\n",
    "    neg_df = bedtool.genome_coverage(dz=True, split=True, strand=\"-\").to_dataframe(names=['chrom', 'loc', 'coverage'])\n",
    "\n",
    "    return pos_df, neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bam_fn = \"/home/gpratt/ad-hoc/chrM_test.bam\"\n",
    "input_bam_fn = \"/home/gpratt/ad-hoc/chrM_input_test.bam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip_bam = pybedtools.BedTool(bam_fn)\n",
    "input_bam = pybedtools.BedTool(input_bam_fn)\n",
    "\n",
    "pos_ip_df, neg_ip_df = make_bigwig_entropy_files.get_stranded_coverage(ip_bam)\n",
    "pos_input_df, neg_input_df = make_bigwig_entropy_files.get_stranded_coverage(input_bam)\n",
    "\n",
    "total_ip = pos_ip_df.coverage.sum() + neg_ip_df.coverage.sum()\n",
    "total_input = pos_input_df.coverage.sum() + neg_input_df.coverage.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df = make_bigwig_entropy_files.combine_ip_input_coverage(pos_ip_df, pos_input_df)\n",
    "\n",
    "del pos_ip_df, pos_input_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedGraphToBigWig /state/partition1/gpratt/8681503.tscc-mgr.local/tmp3rf8Ad /projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes /home/gpratt/ad-hoc/foo.pos.bw\n"
     ]
    }
   ],
   "source": [
    "pos_df = make_bigwig_entropy_files.calculate_coverage_probability(pos_df, total_ip, total_input)\n",
    "pos_df = make_bigwig_entropy_files.calculate_entropy(pos_df)\n",
    "pos_bg = make_bigwig_entropy_files.write_bg(pos_df)\n",
    "make_bigwig_entropy_files.write_bw(pos_bg, \"/home/gpratt/ad-hoc/foo.pos.bw\", '/projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
