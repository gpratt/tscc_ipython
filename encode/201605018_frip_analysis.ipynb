{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_module autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "from itertools import izip\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybedtools\n",
    "import pysam\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from clipper.src import CLIP_analysis\n",
    "from gscripts import qtools\n",
    "from gscripts.encode import encode_helpers\n",
    "from gscripts.general import dataviz\n",
    "from gscripts.rnaseq import splicing_map\n",
    "\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "sns.set_style(\"ticks\")\n",
    "img_dir = \"/home/gpratt/Dropbox/Pratt_Gabriel/PapersInProgress/eCLIP_qc/working_figures/fig_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "legend = None\n",
    "\n",
    "OUTSIDE_LEGEND_SAVEFIG_KWS = dict(bbox_extra_artists=(legend,),\n",
    "                                  bbox_inches='tight')\n",
    "from matplotlib import rc\n",
    "\n",
    "matplotlib.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "rc('text', usetex=False) \n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_norm_dir = \"/projects/ps-yeolab3/encode/analysis/Eric_Input_Norm/\"\n",
    "idr_peak_dir = \"/projects/ps-yeolab3/encode/analysis/Eric_IDR\"\n",
    "split_dir = \"/home/gpratt/projects/idr/analysis/idr_v1/\"\n",
    "out_dir = \"/home/gpratt/projects/encode/analysis/peak_reanalysis_v14/\"\n",
    "frip_out_dir = \"/home/gpratt/projects/encode/analysis/frip_calculations/\"\n",
    "downsample_path = \"/home/gpratt/projects/idr/analysis/downsample_v2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = encode_helpers.get_merged_data()\n",
    "#Filter out anything sequenced after 16/7/18\n",
    "merged_data = merged_data[merged_data['Submitted Date'] < datetime.date(2016, 7, 18)]\n",
    "#Filter out anything not_qced\n",
    "merged_data = merged_data[merged_data.is_qced]\n",
    "#Filter out any data we are planning on submitting, but haven't yet submitted\n",
    "merged_data = merged_data[merged_data.annotation != \"Submit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge rmrep Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get all the counts\n",
    "counts_list = pd.read_csv(\"downsample_counts_full_v4.csv\", dtype={\"RBP_ID\": str, \"bio_rep\": str, \"tech_rep\": str},\n",
    "                         index_col=[\"RBP_ID\", \"RBP\", \"bio_rep\", \"tech_rep\", \"fraction\"])\n",
    "counts_list = counts_list.xs(1.0, level=\"fraction\").groupby(level=['RBP_ID', \"RBP\", \"bio_rep\"]).sum()\n",
    "counts_list.index.rename([\"uID\", \"RBP\", \"rep\"], inplace=True)\n",
    "counts_list.index = counts_list.index.droplevel(\"RBP\")\n",
    "\n",
    "counts_list['rep'] = [\"rep1\" if rep == 1 else \"rep2\" for rep in counts_list.index.get_level_values(level=\"rep\")]\n",
    "counts_list.index = counts_list.index.droplevel(\"rep\")\n",
    "counts_list = counts_list.set_index(\"rep\", append=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = merged_data.reset_index(['Cell line', 'RBP'])\n",
    "\n",
    "merged_data = pd.merge(merged_data, counts_list,\n",
    "        left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "merged_data = merged_data.set_index([\"RBP\", \"Cell line\"], append=True)\n",
    "merged_data = merged_data.reorder_levels(['uID','RBP', 'Cell line','rep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of datasets without reads merged\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print \"number of datasets without reads merged\"\n",
    "print len(merged_data[merged_data.unique.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge regular counts (non-repmapped counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_qc_frame = pd.read_csv(\"/home/gpratt/Dropbox/EricGabe_ENCODE/encode_master_qc.csv\")\n",
    "final_qc_frame = final_qc_frame.fillna(\"\")\n",
    "final_qc_frame['Reads Written Round 2'] = final_qc_frame['Reads Written Round 2'].astype(int)\n",
    "final_qc_frame = final_qc_frame.set_index(keys=[\"rbp\", \"encode_id\", \"rep\", \"cell_type\", \"full_name\", \"barcode\"])\n",
    "filtered_final_qc_frame = final_qc_frame[[ \"Input Reads\", \"Reads Written\", \"repetitive_count\", \"Reads Passing Quality Filter\",\n",
    "                                          \"Uniquely Mapped Reads\", \"Uniquely mapped reads %\", 'Number of reads mapped to too many loci',\n",
    "                                          '% of reads unmapped: too short', '% of reads mapped to too many loci', \"Usable Reads\",\n",
    "                                          \"Fraction Collapsed\", \"Fraction Usable\", \"Num Peaks\", \"Reads Written Round 2\"]]\n",
    "\n",
    "grouped_final_qc_frame = filtered_final_qc_frame.groupby(level=['rbp', 'encode_id', 'rep', 'cell_type', 'full_name']).sum()\n",
    "grouped_final_qc_frame[\"Fraction Collapsed\"] = grouped_final_qc_frame['Usable Reads'] / grouped_final_qc_frame['Uniquely Mapped Reads'].astype(float)\n",
    "grouped_final_qc_frame[\"Fraction Usable\"] = grouped_final_qc_frame['Usable Reads'] / grouped_final_qc_frame['Input Reads'].astype(float)\n",
    "grouped_final_qc_frame = grouped_final_qc_frame.dropna()\n",
    "grouped_final_qc_frame['full_name'] = grouped_final_qc_frame.index.get_level_values(level=\"full_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure we can join input counts\n",
    "fn_label_map = pd.read_table(\"/home/gpratt/projects/encode/scripts/encode_GRCh38_v1.txt\", header=None,\n",
    "              names=['fn', 'species', 'label', 'foo', 'bar', 'baz', 'biz'])\n",
    "fn_label_map['fn_basename'] = fn_label_map.fn.apply(lambda x: os.path.basename(x.split(\";\")[0]).split(\".\")[0])\n",
    "fn_label_map['label'] = fn_label_map.label.apply(lambda x: \"_\".join(x.split(\"_\")[:-1]))\n",
    "\n",
    "#Need to set the full name of the inputs to the actual name of the file, sadly I'm going to do this badly\n",
    "inputs = grouped_final_qc_frame.xs(\"INPUT\", level=\"rep\")    \n",
    "inputs = pd.merge(inputs, fn_label_map,\n",
    "         left_on=\"full_name\", right_on=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error LNG8-M_INPUT_A04F05\n",
      "error LNG8-S_INPUT_C01D08\n",
      "error LNG12-N_INPUT_A04F05\n",
      "error LNG10-M_INPUT_A04F05\n",
      "error LNG10-S_INPUT_C01D08\n",
      "error LNG11-M_INPUT_A04F05\n",
      "error LNG11-S_INPUT_C01D08\n",
      "error LNG9-M_INPUT_A04F05\n",
      "error LNG9-S_INPUT_C01D08\n"
     ]
    }
   ],
   "source": [
    "new_full_name = []\n",
    "for name, row in grouped_final_qc_frame.iterrows():\n",
    "    #print name, row\n",
    "    name = inputs[inputs.label == row.full_name]\n",
    "    if len(name) == 1:\n",
    "        new_full_name.append(name.iloc[0].fn_basename)\n",
    "    elif len(name) == 0:\n",
    "        new_full_name.append(row.full_name)\n",
    "    else:\n",
    "        new_full_name.append(np.nan)\n",
    "        print \"error\", row.full_name\n",
    "grouped_final_qc_frame['full_file_name'] = new_full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data['full_name'] = merged_data.CLIP.apply(lambda x: \"_\".join(os.path.basename(x).split(\"_\")[:-1]))\n",
    "merged_data = merged_data.reset_index()\n",
    "\n",
    "merged_data = pd.merge(merged_data, grouped_final_qc_frame, \n",
    "               left_on=\"full_name\", right_on=\"full_name\", \n",
    "               how=\"left\")\n",
    "\n",
    "merged_data = merged_data.set_index(['uID', 'RBP', 'Cell line', 'rep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Input Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_names = grouped_final_qc_frame.set_index(\"full_file_name\")\n",
    "merged_data['input_file_name'] = merged_data.INPUT.apply(lambda x: os.path.basename(x).split(\".\")[0])\n",
    "merged_data['input_usable'] = merged_data['input_file_name'].apply(lambda x: input_names.ix[x]['Usable Reads'])\n",
    "merged_data['input_name'] = merged_data['input_file_name'].apply(lambda x: input_names.ix[x]['full_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Erics rmduped input reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eric_reads = pd.read_table(\"/home/elvannostrand/data/clip/CLIPseq_analysis/scripts/inline_processing/ENCODE_20170429_newannotations_FINAL.readnumbers.csv\",\n",
    "             names=[\"uID\", \"rep\", \"full_name\", \"same\", \"input_reads_name\", \"input_reads\", \"usable_name\", \"usable\", \n",
    "              \"unique_genome_nonrep_name\", \"unique_genome_nonrep\"])\n",
    "eric_reads = eric_reads.drop([\"usable_name\", \"unique_genome_nonrep_name\", \"input_reads_name\", \"same\"],axis=1)\n",
    "eric_reads['uid'] = eric_reads.full_name.apply(lambda x: \"_\".join(x.split(\"_\")[:-1]))\n",
    "eric_reads = eric_reads.set_index(\"uid\")\n",
    "\n",
    "merged_data['family_map_input_usable'] = merged_data['input_name'].apply(lambda x: eric_reads.ix[x]['input_reads'])\n",
    "#Don't forget that family map input usable is different than unique counts by a bit because I collapse more agressaveily than Eric does (stipping strange muiti-mappers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flag by min read number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arbitray_threshold = 1500000\n",
    "merged_data['passed_ip_read_filter'] = merged_data.unique >= arbitray_threshold\n",
    "merged_data['passed_input_read_filter'] = merged_data.family_map_input_usable > arbitray_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_and_filter_clipper_stringent = functools.partial(encode_helpers.make_and_filter_clipper, l2fc=5, pval=3)\n",
    "make_and_filter_clipper_very_lineant = functools.partial(encode_helpers.make_and_filter_clipper, l2fc=0, pval=1)\n",
    "make_and_filter_clipper_lineant = functools.partial(encode_helpers.make_and_filter_clipper, l2fc=2, pval=1.3)\n",
    "make_and_filter_clipper_moderate = functools.partial(encode_helpers.make_and_filter_clipper, l2fc=3, pval=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 498/498 [00:17<00:00, 27.81it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_data['filtered_moderate'] = merged_data['input_norm'].progress_apply(make_and_filter_clipper_moderate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Can't make this a progress_apply statement because something strange is going on with opening and closing of files\n",
    "merged_data[\"CLIP_counts\"] = merged_data.CLIP.apply(encode_helpers.get_mapped_reads)\n",
    "merged_data[\"INPUT_counts\"] = merged_data.INPUT.apply(encode_helpers.get_mapped_reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate FRiP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_metrics_file(bed_file, out_file=None):\n",
    "    path, ext = os.path.splitext(os.path.basename(bed_file))\n",
    "    if not out_file:\n",
    "        metrics = os.path.join(frip_out_dir, path + \".metrics\")\n",
    "    else:\n",
    "        metrics = out_file\n",
    "    return metrics\n",
    "\n",
    "def format_frip_analysis(bam_file, bed_file, out_file=None):\n",
    "    metrics = format_metrics_file(bed_file, out_file)\n",
    "\n",
    "    return \"python /home/gpratt/gscripts/gscripts/clipseq/calculate_frip.py --bed {} --bam {} --out_file {}\".format(bed_file, bam_file, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "input_out_names = []\n",
    "for name, row in merged_data.iterrows():\n",
    "    if not os.path.exists(format_metrics_file(row.filtered_moderate)):\n",
    "        results.append(format_frip_analysis(row.CLIP, row.filtered_moderate))\n",
    "        \n",
    "    input_out_name = row['filtered_moderate'] + \"input.frip.metrics\"\n",
    "    input_out_names.append(input_out_name)\n",
    "    if not os.path.exists(input_out_name):\n",
    "        results.append(format_frip_analysis(row.INPUT, row.filtered_moderate, input_out_name))\n",
    "\n",
    "#lazy\n",
    "merged_data['input_frip_name'] = input_out_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gpratt/projects/idr/scripts/frip_calculation.sh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running 0 tasks as an array-job.\n"
     ]
    }
   ],
   "source": [
    "job_name = \"frip_calculation\"\n",
    "job = qtools.Submitter(commands=results, \n",
    "                 job_name=\"{}\".format(job_name), \n",
    "                sh_filename=\"/home/gpratt/projects/idr/scripts/{}.sh\".format(job_name),\n",
    "                array=True,\n",
    "                walltime=\"2:00:00\",\n",
    "                out_filename=\"/home/gpratt/projects/idr/scripts/{}.out\".format(job_name),\n",
    "                err_filename=\"/home/gpratt/projects/idr/scripts/{}.err\".format(job_name),\n",
    "                queue=\"home-yeo\")\n",
    "job.job()\n",
    "\n",
    "print \"/home/gpratt/projects/idr/scripts/{}.sh\".format(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_frip_metrics(fn):\n",
    "    return pd.read_table(fn).ix[0]\n",
    "\n",
    "def parse_frip_metrics_ip(fn):\n",
    "    return parse_frip_metrics(format_metrics_file(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 498/498 [00:16<00:00, 29.85it/s]\n",
      "Progress: 100%|██████████| 498/498 [00:13<00:00, 35.69it/s]\n"
     ]
    }
   ],
   "source": [
    "ip_frip_df = merged_data.filtered_moderate.progress_apply(parse_frip_metrics_ip)\n",
    "input_frip_df = merged_data.input_frip_name.progress_apply(parse_frip_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, ip_frip_df,\n",
    "        left_index=True, right_index=True)\n",
    "\n",
    "merged_data = pd.merge(merged_data, input_frip_df, \n",
    "                       left_index=True, right_index=True,\n",
    "                      suffixes=(\"_ip\", \"_input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Entropy to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotated_bedtool_header = ['chrom', 'start', \"stop\", \"name\", \"score\", \"strand\", \"annotation\", \"gene_id\"]\n",
    "full_header = [\"chrom\", \"start\", \"stop\", \"full_name\", \"ip_reads\", \"input_reads\", \"p_val\", \"chisq\", \"test_type\", \n",
    "               \"enrichment\", \"log10_p_val\", \"log2_fold_change\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_full_from_annotated(fn):\n",
    "    stripped_fn = \".\".join(fn.split(\".\")[:-3])\n",
    "    return stripped_fn + \".full.compressed2.bed.full\"\n",
    "\n",
    "def calculate_entropy(row, total_ip_reads, total_input_reads):\n",
    "    p_ip = float(row.ip_reads) / total_ip_reads\n",
    "    p_input = float(row.input_reads) / total_input_reads\n",
    "    \n",
    "    return p_ip * np.log2(p_ip / p_input)\n",
    "\n",
    "def get_entropy_from_annotated(fn):\n",
    "    fn = os.path.basename(fn)\n",
    "    stripped_fn = \".\".join(fn.split(\".\")[:-3])\n",
    "    stripped_fn = os.path.join(out_dir, stripped_fn)\n",
    "    return stripped_fn + \".full.compressed2.bed.full.entropy.bed\"\n",
    "\n",
    "def sum_entropy(filtered_peaks, original_peaks):\n",
    "    entropy = pd.read_table(get_entropy_from_annotated(original_peaks))\n",
    "    filtered_peaks = pd.read_table(filtered_peaks, names=annotated_bedtool_header)\n",
    "\n",
    "    merged_peaks = pd.merge(filtered_peaks, entropy, \n",
    "             left_on=['chrom', 'start', 'stop'],\n",
    "             right_on=['chrom', 'start', 'stop'])\n",
    "\n",
    "    return merged_peaks.entropy.sum()\n",
    "\n",
    "def sum_entropy_row(row):\n",
    "    #Sadly the majority of the time in this operation is opening the files, can't make it faster :(\n",
    "    return sum_entropy(row.filtered_moderate, row['input_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [00:15<00:00, 31.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, row in tqdm(list(merged_data.iterrows())):    \n",
    "    full_fn = get_full_from_annotated(row['input_norm'])\n",
    "    out_fn = os.path.join(out_dir, os.path.basename(full_fn) + \".entropy.bed\")\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "\n",
    "    ip_reads = row['CLIP_counts']\n",
    "    input_reads = row['INPUT_counts']\n",
    "\n",
    "    read_counts = pd.read_table(full_fn, names=full_header)\n",
    "    \n",
    "    tool = functools.partial(calculate_entropy, total_ip_reads=ip_reads, total_input_reads=input_reads)\n",
    "    read_counts['entropy'] = read_counts.apply(tool, axis=1)\n",
    "    read_counts.to_csv(out_fn, sep=\"\\t\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 498it [15:49,  3.71s/it]                       \n"
     ]
    }
   ],
   "source": [
    "merged_data['entropy'] = merged_data.progress_apply(sum_entropy_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Reproducable Information with reads mapping to repetitive elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_elements = pd.read_table(\"/home/elvannostrand/data/clip/CLIPseq_analysis/scripts/inline_processing/20170505.ALLENCODEinclnotsubmitted.txt.nopipes.txt\",\n",
    "                            header=0, names= [\"element\", \"file\",\"something\", \"clip_count\", \"clip_rpr\", \"input_count\", \"input_rpr\", \"fold-enrichment\", \"information content\"])\n",
    "merged_data['ip_raw_names'] = merged_data.CLIP.apply(lambda x: os.path.basename(x).split(\".\")[0])\n",
    "important_reads = merged_data[['ip_raw_names', 'family_map_input_usable', 'unique']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entropy_to_ignore = set([\n",
    "    'unique_3utr',\n",
    "    'unique_5utr',\n",
    "    'unique_5utr_and_3utr',\n",
    "    'unique_CDS',\n",
    "    'unique_antisense_gencode',\n",
    "    'unique_distintron',\n",
    "    'unique_intergenic',\n",
    "    'unique_noncoding_distintron',\n",
    "    'unique_noncoding_exon',\n",
    "    'unique_noncoding_proxintron',\n",
    "    'unique_proxintron',\n",
    "    'chrM',\n",
    "    'antisense_chrM',])\n",
    "\n",
    "entropy_to_use = list(set(rep_elements.element) - entropy_to_ignore)\n",
    "rep_elements = rep_elements[rep_elements.element.isin(entropy_to_use)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chisq_value(row):\n",
    "    \"Calculates Chiseq values for all the reptitive elements\"\n",
    "    clip_total = row['unique'] - row.clip_count \n",
    "    input_total = row.family_map_input_usable - row.input_count\n",
    "\n",
    "    g, p, dof, expctd = scipy.stats.chi2_contingency([[row.clip_count, clip_total], [row.input_count, input_total]])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rep_elements = pd.merge(rep_elements, important_reads, left_on=\"file\", right_on=\"ip_raw_names\")\n",
    "rep_elements['p_val'] = rep_elements.apply(get_chisq_value, axis=1)\n",
    "rep_elements['log10_p_val'] = rep_elements['p_val'].apply(lambda x: np.log10(x) * -1)\n",
    "rep_elements.loc[np.isinf(rep_elements.log10_p_val), \"log10_p_val\"] = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig_rep_elements = rep_elements[((rep_elements['log10_p_val'] > 3) & (rep_elements['fold-enrichment'] > 3)) | ((rep_elements.clip_rpr > .4) & (rep_elements['fold-enrichment'] > 1))]\n",
    "rep_element_information = sig_rep_elements.groupby(\"file\").sum()\n",
    "rep_element_information = rep_element_information.drop([\"fold-enrichment\", \"family_map_input_usable\", \"unique\", \"p_val\", \"log10_p_val\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = merged_data.reset_index()\n",
    "\n",
    "#Some RBPs don't have any rep elements enriched, so I'm just saying they have 0 entropy\n",
    "merged_data = pd.merge(merged_data, rep_element_information, left_on=\"ip_raw_names\", right_index=True, how=\"left\")\n",
    "merged_data = merged_data.set_index(['uID', 'RBP', 'Cell line', 'rep'])\n",
    "merged_data = merged_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Analysis for General Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def thresholding_plotter(threshold_col, actual_classification, df, out_fig=\"\"):\n",
    "    df['submitted_plot'] = [\"Passed\" if submitted else \"Failed\" for submitted in df[actual_classification]]\n",
    "    df['group'] = 1\n",
    "    \n",
    "    true_positive_array, false_positive_array, threshold_array, best_threshold = encode_helpers.get_best_f_score(threshold_col, \n",
    "                                                                                              true_clasification_col= actual_classification,\n",
    "                                                                                              df=df)\n",
    "\n",
    "        \n",
    "    num_rows = 1\n",
    "    num_cols = 2\n",
    "    with dataviz.Figure(os.path.join(img_dir, \"{}_distribution.svg\".format(out_fig)), figsize=(2.5 * num_cols, 2.5*num_rows)) as fig:\n",
    "        ax = fig.add_subplot(num_rows, num_cols, 1)\n",
    "        sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", data=df, ax=ax, alpha=.7, size=2, linewidth=.1)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.axhline(best_threshold, color=\".7\", linewidth=1.5, linestyle=\"--\")\n",
    "        ax.set_ylim(0,)\n",
    "        [tick.set_fontsize(8) for tick in ax.get_xticklabels()]\n",
    "        [tick.set_fontsize(8) for tick in ax.get_yticklabels()]\n",
    "        ax.set_ylabel(\"Entropy\", fontsize=8)\n",
    "        ax.set_title(\"Entropy in eCLIP datasets\", fontsize=8)\n",
    "        \n",
    "        ax = fig.add_subplot(num_rows, num_cols, 2)\n",
    "        sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", \n",
    "                      data=df[df[threshold_col] < .7], alpha=.7, size=2, linewidth=.1, ax=ax)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_ylabel(\"\", fontsize=8)\n",
    "\n",
    "        ax.axhline(best_threshold, color=\".7\", linewidth=1.5, linestyle=\"--\")\n",
    "        ax.set_ylim(0,.7)\n",
    "        ax.axhline()\n",
    "        [tick.set_fontsize(8) for tick in ax.get_xticklabels()]\n",
    "        [tick.set_fontsize(8) for tick in ax.get_yticklabels()]\n",
    "        \n",
    "    num_rows = 1\n",
    "    num_cols = 3\n",
    "    with dataviz.Figure(os.path.join(img_dir, \"{}_reproducibility_test_passed_qc.svg\".format(out_fig)), figsize=(3 * num_cols, 3 * num_rows)) as fig:\n",
    "        ax = fig.add_subplot(1,3,1)\n",
    "        ax.plot(false_positive_array, true_positive_array, label=\"ROC Curve\")\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.plot([0,1], [0,1], label=\"Null Expectation\") \n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_title(\"ROC Curve\")\n",
    "        ax.legend()\n",
    "\n",
    "        ax = fig.add_subplot(1,3,2)\n",
    "        ax.plot(threshold_array, true_positive_array)\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.set_xlabel(\"Threshold\")\n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_title(\"ROC Curve\")\n",
    "        ax.axvline(best_threshold)\n",
    "\n",
    "        ax = fig.add_subplot(1,3,3)\n",
    "        ax.plot(threshold_array, false_positive_array)\n",
    "        ax.set_ylabel(\"False Positive Rate\")\n",
    "        ax.set_xlabel(\"Threshold\")\n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_title(\"ROC Curve\")\n",
    "        ax.axvline(best_threshold)\n",
    "\n",
    "    print encode_helpers.confusion_numbers(best_threshold, threshold_col, true_clasification_col= actual_classification, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thresholding_plotter_presentation(threshold_col, actual_classification, df, out_fig=\"\"):\n",
    "    df['submitted_plot'] = [\"Passed\" if submitted else \"Failed\" for submitted in df[actual_classification]]\n",
    "    df['group'] = 1\n",
    "    \n",
    "    true_positive_array, false_positive_array, threshold_array, best_threshold = encode_helpers.get_best_f_score(threshold_col, \n",
    "                                                                                              true_clasification_col= actual_classification,\n",
    "                                                                                              df=df)\n",
    "\n",
    "        \n",
    "    num_rows = 1\n",
    "    num_cols = 2\n",
    "    with dataviz.Figure(os.path.join(img_dir, \"{}_distribution_presentation.svg\".format(out_fig)), figsize=(4 * num_cols, 4*num_rows)) as fig:\n",
    "        ax = fig.add_subplot(num_rows, num_cols, 1)\n",
    "        sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", data=df, \n",
    "                      ax=ax, alpha=.7, size=5, linewidth=0)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.axhline(best_threshold, color=\".7\", linewidth=3, linestyle=\"--\")\n",
    "        ax.set_ylim(0,)\n",
    "        ax.legend(fontsize=20)\n",
    "        [tick.set_fontsize(20) for tick in ax.get_xticklabels()]\n",
    "        [tick.set_fontsize(20) for tick in ax.get_yticklabels()]\n",
    "        ax.set_ylabel(\"Entropy\", fontsize=20)\n",
    "        ax.set_title(\"Entropy in eCLIP datasets\", fontsize=20)\n",
    "        \n",
    "        ax = fig.add_subplot(num_rows, num_cols, 2)\n",
    "        sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", \n",
    "                      data=df[df[threshold_col] < .7], alpha=.7, size=7, linewidth=0, ax=ax)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_ylabel(\"\", fontsize=20)\n",
    "\n",
    "        ax.axhline(best_threshold, color=\".7\", linewidth=3, linestyle=\"--\")\n",
    "        ax.set_ylim(0,.5)\n",
    "        ax.axhline()\n",
    "        [tick.set_fontsize(20) for tick in ax.get_xticklabels()]\n",
    "        [tick.set_fontsize(20) for tick in ax.get_yticklabels()]\n",
    "        ax.legend(fontsize=20)\n",
    "\n",
    "    num_rows = 1\n",
    "    num_cols = 3\n",
    "    with dataviz.Figure(os.path.join(img_dir, \"{}_reproducibility_test_passed_qc_presentation.svg\".format(out_fig)), figsize=(4 * num_cols, 4 * num_rows)) as fig:\n",
    "        ax = fig.add_subplot(1,3,1)\n",
    "        ax.plot(false_positive_array, true_positive_array, label=\"ROC Curve\", linewidth=5)\n",
    "        ax.set_ylabel(\"True Positive Rate\", fontsize=20)\n",
    "        ax.set_xlabel(\"False Positive Rate\", fontsize=20)\n",
    "        ax.plot([0,1], [0,1], label=\"Null Expectation\") \n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_title(\"ROC Curve\", fontsize=20)\n",
    "        ax.legend(fontsize=20)\n",
    "        [tick.set_fontsize(20) for tick in ax.get_xticklabels()]\n",
    "        [tick.set_fontsize(20) for tick in ax.get_yticklabels()]\n",
    "\n",
    "        ax = fig.add_subplot(1,3,2)\n",
    "        ax.plot(threshold_array, true_positive_array, linewidth=5)\n",
    "        ax.set_ylabel(\"True Positive Rate\", fontsize=20)\n",
    "        ax.set_xlabel(\"Threshold\", fontsize=20)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_title(\"ROC Curve\", fontsize=20)\n",
    "        ax.axvline(best_threshold)\n",
    "\n",
    "        ax = fig.add_subplot(1,3,3)\n",
    "        ax.plot(threshold_array, false_positive_array)\n",
    "        ax.set_ylabel(\"False Positive Rate\", fontsize=20)\n",
    "        ax.set_xlabel(\"Threshold\", fontsize=20)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.set_title(\"ROC Curve\", fontsize=20)\n",
    "        ax.axvline(best_threshold)\n",
    "\n",
    "    print encode_helpers.confusion_numbers(best_threshold, threshold_col, true_clasification_col= actual_classification, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Count Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(row):\n",
    "    p = row.reads_in_peaks_ip / row.total_reads_ip\n",
    "    q = row.reads_in_peaks_input / row.total_reads_input\n",
    "\n",
    "    return p * np.log2(p/q)\n",
    "merged_data['single_count_entropy'] = merged_data.apply(calc_entropy, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducable Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/ps-yeolab3/encode/analysis/Eric_IDR/374.01v02.IDR.out.0102merged.bed.annotated_proxdist.entropy\n"
     ]
    }
   ],
   "source": [
    "#This doesn't work because Eric hasn't run his entropy annotator for 374\n",
    "def get_entropy(fn):\n",
    "    if not os.path.exists(fn):\n",
    "        print fn\n",
    "        return 0\n",
    "    \n",
    "    df = pd.read_table(fn, names=['chrom', 'start', 'stop', \n",
    "                                  'l2fc', 'pval', 'strand', \n",
    "                                  'annotation', 'annotation_v2', \n",
    "                                  'gene_id', 'entropy'])\n",
    "    return df.entropy.sum()\n",
    "\n",
    "merged_data['idr_peaks'] = merged_data.index.get_level_values(level=\"uID\").map(lambda x: os.path.join(idr_peak_dir, \"{}.01v02.IDR.out.0102merged.bed.annotated_proxdist.entropy\".format(x)))\n",
    "\n",
    "idr_datasets = merged_data.xs(\"rep1\", level=3).copy()\n",
    "idr_datasets['rep_entropy'] = merged_data['information content'].groupby(level=['uID', 'RBP', 'Cell line']).mean()\n",
    "idr_datasets['total_entropy'] = idr_datasets['idr_peaks'].apply(get_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# em_peaks_dir = \"/home/gpratt/projects/idr/analysis/input_em_peaks\"\n",
    "\n",
    "# def get_entropy_bed(fn):\n",
    "#     if not os.path.exists(fn):\n",
    "#         return 0\n",
    "#     df = pd.read_table(fn, names=['chrom', 'start', 'stop', 'l2fc', \n",
    "#                                   'pval', 'strand', 'entropy'])\n",
    "#     return df.entropy.sum()\n",
    "\n",
    "# merged_data['input_norm_em'] = merged_data['input_norm'].apply(lambda x: os.path.join(em_peaks_dir, \".\".join(os.path.basename(x).split(\".\")[:2]) + \".peaks.em.v3.bed\"))\n",
    "# merged_data['input_norm_em_filtered'] = merged_data['input_norm_em'].progress_apply(make_and_filter_clipper_moderate)\n",
    "# merged_data['input_norm_em_entropy'] = merged_data['input_norm_em_filtered'].progress_apply(get_entropy_bed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add IDR Label to merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idr_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b9c8c1f1c309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midr_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'idr_results' is not defined"
     ]
    }
   ],
   "source": [
    "idr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idr_results = pd.read_csv(\"/home/gpratt/ipython_notebook/encode/idr_results.csv\", header=[0,1], index_col=[0,1,2])\n",
    "result = []\n",
    "for index_1, index_2 in idr_results.columns:\n",
    "    if index_2.startswith(\"Unnamed\"):\n",
    "        index_2 = \"\"\n",
    "    result.append([index_1, index_2])\n",
    "idr_results.columns = pd.MultiIndex.from_tuples(result)\n",
    "\n",
    "important_cols = ['pesudoreplicate_count_v2',\n",
    "                  'rep1_count_v2', \n",
    "                  'rep2_count_v2', \n",
    "                  'replicate_count_v2', \n",
    "                  'reproducibility_test_v2',\n",
    "                  'rescue_ratio_v2',\n",
    "                  'self_consistency_ratio_v2',\n",
    "                 ]\n",
    "idr_results = idr_results[important_cols]\n",
    "idr_results.columns = idr_results.columns.get_level_values(level=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idr_results = idr_results.reset_index()\n",
    "merged_data = merged_data.reset_index()\n",
    "merged_data = pd.merge(merged_data, idr_results, \n",
    "         left_on=['uID', 'Cell line', 'RBP'], right_on=['uID', 'Cell line', 'RBP'], how=\"left\")\n",
    "merged_data = merged_data.set_index(['uID', 'RBP', 'Cell line', 'rep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in rep element data to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data[\"frip_rep\"] = merged_data['FRiP_ip'] + merged_data['clip_rpr']\n",
    "merged_data['entropy_rep_exp'] = merged_data['entropy'] + merged_data['information content']\n",
    "# merged_data['clip_rep_entropy_em'] = merged_data['input_norm_em_entropy'] + merged_data['information content']\n",
    "idr_datasets['peak_rep_entropy'] = idr_datasets['rep_entropy'] + idr_datasets['total_entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Merged Data for plotting of frip-like analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data_read_filtered = merged_data[merged_data.passed_ip_read_filter & merged_data.passed_input_read_filter].copy()\n",
    "\n",
    "filtered_data = merged_data_read_filtered.groupby(level=[\"uID\", 'RBP', \"Cell line\"]).count().CLIP\n",
    "idr_datasets_read_filtered = idr_datasets.ix[filtered_data[filtered_data == 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic FRIP Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholding_plotter(\"FRiP_ip\", \"generally_submittable\", merged_data_read_filtered, out_fig=\"FRiP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ask given FRiP scores calculated for each dataset, and our hand annotated success vs fail metric we defined, can we use FRiP to predict if a dataset will pass or fail.  I generated a confusion matrix, and calculated an f-score for each cutoff possible.  I Also plotted the true positive and false positive rate.  I was able to achieve a fairly high true positive rate, but the descriminatory power was low overall.  The strongest thing I can say about this, is we've got a method that might be useful as a smell test.  \n",
    "\n",
    "I'll try explanied entropy next.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long story short, the FRiP score isn't a good tool to identify good and bad datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRiP Analysis + Repetitive Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholding_plotter(\"frip_rep\", \"generally_submittable\", merged_data_read_filtered, out_fig=\"FRiP_rep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does Entropy Work better than FRiP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholding_plotter(\"entropy\", \"generally_submittable\", merged_data_read_filtered, out_fig=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholding_plotter_presentation(\"entropy\", \"generally_submittable\", merged_data_read_filtered, out_fig=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df =merged_data_read_filtered\n",
    "threshold_col = \"entropy\"\n",
    "actual_classification = \"generally_submittable\"\n",
    "out_fig = \"foo_unlabeled\"\n",
    "\n",
    "df['submitted_plot'] = [\"Passed\" if submitted else \"Failed\" for submitted in df[actual_classification]]\n",
    "df['group'] = 1\n",
    "\n",
    "\n",
    "num_rows = 1\n",
    "num_cols = 2\n",
    "best_threshold = .044\n",
    "\n",
    "plotting_cutoff = .5\n",
    "with dataviz.Figure(os.path.join(img_dir, \"{}_distribution_presentation.svg\".format(out_fig)), figsize=(4 * num_cols, 4*num_rows)) as fig:\n",
    "    ax = fig.add_subplot(num_rows, num_cols, 1)\n",
    "    sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", data=df, \n",
    "                  ax=ax, alpha=.7, size=6, linewidth=0)\n",
    "    sns.despine(ax=ax)\n",
    "    #ax.axhline(best_threshold, color=\".7\", linewidth=5, linestyle=\"--\")\n",
    "    ax.set_ylim(0,)\n",
    "    ax.legend(fontsize=20)\n",
    "    [tick.set_fontsize(20) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(20) for tick in ax.get_yticklabels()]\n",
    "    ax.set_ylabel(\"Entropy\", fontsize=20)\n",
    "    ax.set_title(\"Entropy in eCLIP datasets\", fontsize=20)\n",
    "\n",
    "    ax = fig.add_subplot(num_rows, num_cols, 2)\n",
    "    sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", \n",
    "                  data=df[df[threshold_col] < plotting_cutoff], alpha=.7, size=5, linewidth=0, ax=ax)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_ylabel(\"\", fontsize=20)\n",
    "\n",
    "    #ax.axhline(best_threshold, color=\".7\", linewidth=6, linestyle=\"--\")\n",
    "    ax.set_ylim(0, plotting_cutoff)\n",
    "    ax.axhline()\n",
    "    [tick.set_fontsize(20) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(20) for tick in ax.get_yticklabels()]\n",
    "    ax.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = merged_data_read_filtered\n",
    "threshold_col = \"entropy\"\n",
    "actual_classification = \"generally_submittable\"\n",
    "out_fig = \"foo\"\n",
    "\n",
    "df['submitted_plot'] = [\"Passed\" if submitted else \"Failed\" for submitted in df[actual_classification]]\n",
    "df['group'] = 1\n",
    "\n",
    "\n",
    "num_rows = 1\n",
    "num_cols = 2\n",
    "best_threshold = .044\n",
    "\n",
    "plotting_cutoff = .5\n",
    "with dataviz.Figure(os.path.join(img_dir, \"{}_distribution_presentation.svg\".format(out_fig)), figsize=(4 * num_cols, 4*num_rows)) as fig:\n",
    "    ax = fig.add_subplot(num_rows, num_cols, 1)\n",
    "    sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", data=df, \n",
    "                  ax=ax, alpha=.7, size=6, linewidth=0)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.axhline(best_threshold, color=\".7\", linewidth=5, linestyle=\"--\")\n",
    "    ax.set_ylim(0,)\n",
    "    ax.legend(fontsize=20)\n",
    "    [tick.set_fontsize(20) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(20) for tick in ax.get_yticklabels()]\n",
    "    ax.set_ylabel(\"Entropy\", fontsize=20)\n",
    "    ax.set_title(\"Entropy in eCLIP datasets\", fontsize=20)\n",
    "\n",
    "    ax = fig.add_subplot(num_rows, num_cols, 2)\n",
    "    sns.swarmplot(x=\"group\", y=threshold_col, hue=\"submitted_plot\", \n",
    "                  data=df[df[threshold_col] < plotting_cutoff], alpha=.7, size=5, linewidth=0, ax=ax)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_ylabel(\"\", fontsize=20)\n",
    "\n",
    "    ax.axhline(best_threshold, color=\".7\", linewidth=6, linestyle=\"--\")\n",
    "    ax.set_ylim(0, plotting_cutoff)\n",
    "    ax.axhline()\n",
    "    [tick.set_fontsize(20) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(20) for tick in ax.get_yticklabels()]\n",
    "    ax.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try with just true positives that we pass due to peaks\n",
    "peaks_and_negatives = merged_data_read_filtered[~merged_data_read_filtered.family_mapping_submitable]\n",
    "thresholding_plotter(\"entropy\", \"generally_submittable\", peaks_and_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp = peaks_and_negatives[(peaks_and_negatives.entropy >= 0.044) & ~peaks_and_negatives.generally_submittable]\n",
    "fp_grp = fp.groupby(level=['uID', \"RBP\", 'Cell line']).count().CLIP >= 2\n",
    "fp_grp[fp_grp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 experiments in total are false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = peaks_and_negatives[(peaks_and_negatives.entropy < 0.044) & peaks_and_negatives.generally_submittable]\n",
    "fn.groupby(level=['uID', \"RBP\", 'Cell line']).count().CLIP >= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 datasets are false negatives, 7 are reproducably bad in both reps, and are broad binders, 8 are negatives in one dataset or another, I'll need to look into why these datasets are bad.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy + Repetitive Elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholding_plotter(\"entropy_rep_exp\", \"generally_submittable\", merged_data_read_filtered, out_fig=\"entropy_rep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Count Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholding_plotter(\"single_count_entropy\", \"generally_submittable\", merged_data_read_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thresholding_plotter(\"input_norm_em_entropy\", \"generally_submittable\", merged_data_read_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM Entropy + Repetitive Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thresholding_plotter(\"clip_rep_entropy_em\", \"generally_submittable\", merged_data_read_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducable peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thresholding_plotter(\"total_entropy\", \"generally_submittable\", idr_datasets_read_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reproducable Entropy + Repetitive Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thresholding_plotter(\"peak_rep_entropy\", \"generally_submittable\", idr_datasets_read_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merged_data.to_csv(\"/home/gpratt/Dropbox/ENCODE_FINAL_ANNOTATIONS_PEAKS_IDR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various families have very different information content paramaters, so I think I'll probably have to classify for each family independently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 246 -- need to check QC numbers, MT-trna binding, am I capturing this? Is this being lost due to my re-assignments?\n",
    "1. 311 -- no notes as to why passed\n",
    "1. 358 rep2 -- tRNAs not quite enriched... maybe need to create a better thresholding system for each element?\n",
    "1. 461 rep1 -- rep1 peaks aren't as enriched as rep2 peaks.  Also the repetitive elements kind of suck.  I might 1. actually want to fail this dataset due to lack of repdoucabilty...\n",
    "1. 470 rep1 -- rep1 peaks aren't as enriched as rep2 peaks.  I might actually want to fail this dataset due to lack of repdoucabilty...\n",
    "1. 550 rep2 -- rep2 peaks aren't as enriched as rep1 peaks.  I might actually want to fail this dataset due to lack of repdoucabilty..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passed entropy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data['passed_entropy'] = merged_data.entropy >= .044\n",
    "\n",
    "passed_exp_entropy = merged_data.groupby(level=['uID', 'RBP', 'Cell line']).apply(lambda x: all([all(x['passed_entropy']),\n",
    "                                                                                                 all(x['passed_ip_read_filter']),\n",
    "                                                                                                 all(x['passed_input_read_filter'])]))\n",
    "passed_exp_entropy = passed_exp_entropy.rename(\"passed_exp\")\n",
    "passed_exp_entropy = passed_exp_entropy.reset_index()\n",
    "\n",
    "merged_data = merged_data.reset_index()\n",
    "merged_data = pd.merge(merged_data, passed_exp_entropy,\n",
    "         left_on=['uID', 'Cell line', 'RBP'], right_on=['uID', 'Cell line', 'RBP'], how=\"left\")\n",
    "merged_data = merged_data.set_index(['uID', 'RBP', 'Cell line', 'rep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding False Positives and False Negatives for Basic Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_level_fn = merged_data[merged_data.passed_ip_read_filter & merged_data.passed_input_read_filter & merged_data.generally_submittable & ~merged_data.passed_exp]\n",
    "peak_level_fp = merged_data[merged_data.passed_ip_read_filter & merged_data.passed_input_read_filter & ~merged_data.generally_submittable & merged_data.passed_exp]\n",
    "peak_level_tp = merged_data[merged_data.passed_ip_read_filter & merged_data.passed_input_read_filter & merged_data.generally_submittable & merged_data.passed_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_level_fn[['entropy', 'notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_level_fp[['entropy', 'notes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Of the datasets passed, how many of them would then fail via IDR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_level_fp_grp = peak_level_fp.groupby(level=['uID', 'RBP', 'Cell line'])\n",
    "peak_level_fp_rep1 = peak_level_fp_grp.first()\n",
    "peak_level_fp_rep1 = peak_level_fp_rep1[peak_level_fp_grp.count().CLIP == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_level_fp_rep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "num_cols = 1\n",
    "with dataviz.Figure(os.path.join(img_dir, \"false_positives.svg\"), figsize=(2.5 * num_cols, 2.5 * num_rows)) as fig:\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(\"Reproducablity Test\")\n",
    "    #ax.set_title(\"Number of replicates\\npassing reproducibility test\", fontsize=18)\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    sns.factorplot(x='reproducibility_test_v2', \n",
    "                   kind='count', \n",
    "                   data=peak_level_fp_rep1, \n",
    "                   order=[\"pass\", \"borderline\", \"fail\"],\n",
    "                   ax=ax\n",
    "                  )\n",
    "\n",
    "    ax.set_ylabel(\"Number of Datasets\", fontsize=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    [tick.set_fontsize(14) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(14) for tick in ax.get_yticklabels()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#peak_level_fp_rep1[peak_level_fp_rep1.reproducibility_test_v2 == \"pass\"]['notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peak_level_tp_grp = peak_level_tp.groupby(level=['uID', 'RBP', 'Cell line'])\n",
    "peak_level_tp_rep1 = peak_level_tp_grp.first()\n",
    "peak_level_tp_rep1 = peak_level_tp_rep1[peak_level_tp_grp.count().CLIP == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "num_cols = 1\n",
    "with dataviz.Figure(os.path.join(img_dir, \"reproducibility_test_tp.svg\"), figsize=(2.5 * num_cols, 2.5 * num_rows)) as fig:\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(\"Reproducablity Test\")\n",
    "    #ax.set_title(\"True Positives\\npassing reproducibility test\", fontsize=18)\n",
    "    sns.despine(ax=ax)\n",
    "    \n",
    "    sns.factorplot(x='reproducibility_test_v2', \n",
    "                   kind='count', \n",
    "                   data=peak_level_tp_rep1, \n",
    "                   order=[\"pass\", \"borderline\", \"fail\"],\n",
    "                   ax=ax\n",
    "                  )\n",
    "    \n",
    "    #ax.set_ylabel(\"Number of Datasets\", fontsize=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    [tick.set_fontsize(14) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(14) for tick in ax.get_yticklabels()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#peak_level_tp_rep1[peak_level_tp_rep1.reproducibility_test_v2_y == \"fail\"]['notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_data = merged_data.xs(\"rep1\", level=\"rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_data.loc[(exp_data.generally_submittable & exp_data.passed_exp), 'classification'] = 'True Positive'\n",
    "exp_data.loc[(~exp_data.generally_submittable & exp_data.passed_exp), 'classification'] = 'False Positive'\n",
    "exp_data.loc[(exp_data.generally_submittable & ~exp_data.passed_exp), 'classification'] = 'False Negative'\n",
    "exp_data.loc[(~exp_data.generally_submittable & ~exp_data.passed_exp), 'classification'] = 'True Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "num_cols = 1\n",
    "with dataviz.Figure(os.path.join(img_dir, \"reproducibility_test_presentation.svg\"), figsize=(5 * num_cols, 5 * num_rows)) as fig:\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(\"Reproducablity Test\")\n",
    "    ax.set_title(\"Number of replicates\\npassing reproducibility test\", fontsize=18)\n",
    "    sns.despine(ax=ax)\n",
    "    \n",
    "    sns.factorplot(x='reproducibility_test_v2', \n",
    "                   hue=\"classification\",\n",
    "                   kind='count', \n",
    "                   data=exp_data, \n",
    "                   order=[\"pass\", \"borderline\", \"fail\"],\n",
    "                   hue_order=['True Positive', 'False Positive', 'False Negative', 'True Negative'],\n",
    "                   ax=ax\n",
    "                  )\n",
    "    \n",
    "    ax.set_ylabel(\"Number of Datasets\", fontsize=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.legend(fontsize=18)\n",
    "    [tick.set_fontsize(14) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(14) for tick in ax.get_yticklabels()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "num_cols = 1\n",
    "with dataviz.Figure(os.path.join(img_dir, \"reproducibility_test.svg\"), figsize=(2.5 * num_cols, 2.5 * num_rows)) as fig:\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(\"Reproducablity Test\")\n",
    "    ax.set_title(\"Number of replicates\\npassing reproducibility test\", fontsize=8)\n",
    "    sns.despine(ax=ax)\n",
    "    \n",
    "    sns.factorplot(x='reproducibility_test_v2', \n",
    "                   hue=\"classification\",\n",
    "                   kind='count', \n",
    "                   data=exp_data, \n",
    "                   order=[\"pass\", \"borderline\", \"fail\"],\n",
    "                   hue_order=['True Positive', 'False Positive', 'False Negative', 'True Negative'],\n",
    "                   ax=ax\n",
    "                  )\n",
    "    \n",
    "    ax.set_ylabel(\"Number of Datasets\", fontsize=8)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.legend(fontsize=8)\n",
    "    [tick.set_fontsize(8) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(8) for tick in ax.get_yticklabels()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Use just basic entropy to classify RBPs.\n",
    "1. Need to look into why the false negatives are false negatives\n",
    "    - Broad Binders generally, don't need to worry\n",
    "1. How many false positives are kept around after only taking both replicates \n",
    "    - on par with IDR filtering \n",
    "1. Need to look at IDR filtering on all datasets after, how many datasets get passed or failed due to the new IDR approach. \n",
    "    - done slightly better\n",
    "1. Need to see if its worth coming up with a different classifier for just the datasets with repetitive elements\n",
    "    - No they get classified nicely \n",
    "1. Need to see if there is some sort of other filtering criteria I can apply to the false positives\n",
    "   - Still looking into this\n",
    "1. Need to check on that final non-submitted dataset --re-running, very slow...\n",
    "    - done\n",
    "1. Need to re-do the final model I come up with on a training and test dataset to show accuracy\n",
    "    - done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Matrix of QC results for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_frame = merged_data[['passed_ip_read_filter',\n",
    "                            'passed_input_read_filter', \n",
    "                            'passed_entropy', \n",
    "                            #'reproducibility_test_v2', \n",
    "                            #'passed_exp_entropy'\n",
    "                           ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(output_frame.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fscore for final thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_helpers.get_best_f_score??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = merged_data.xs(\"rep1\", level=\"rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(foo.generally_submittable, (foo.reproducibility_test_v2.isin([\"pass\"]) & foo.passed_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(foo.generally_submittable, (foo.reproducibility_test_v2.isin([\"pass\", \"borderline\"]) & foo.passed_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp_final = foo[foo.generally_submittable & (foo.reproducibility_test_v2.isin([\"pass\", \"borderline\"]) & foo.passed_exp)]\n",
    "fp_final = foo[~foo.generally_submittable & (foo.reproducibility_test_v2.isin([\"pass\", \"borderline\"]) & foo.passed_exp)]\n",
    "fn_final = foo[foo.generally_submittable & ~(foo.reproducibility_test_v2.isin([\"pass\", \"borderline\"]) & foo.passed_exp)]\n",
    "tn_final = foo[~foo.generally_submittable & ~(foo.reproducibility_test_v2.isin([\"pass\", \"borderline\"]) & foo.passed_exp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with dataviz.Figure(os.path.join(img_dir, \"submittable.svg\"), figsize=(2.5 * num_cols, 2.5 * num_rows)) as fig:\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    sns.countplot(x=\"generally_submittable\", data=foo, ax=ax)\n",
    "    [tick.set_fontsize(18) for tick in ax.get_xticklabels()]\n",
    "    [tick.set_fontsize(18) for tick in ax.get_yticklabels()]\n",
    "    ax.set_ylabel(\"All Experiments\", fontsize=18)\n",
    "    ax.set_xticklabels(['Rejected', 'Passed'])\n",
    "    ax.set_xlabel(\"\")\n",
    "    sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(foo[foo.generally_submittable])\n",
    "print len(foo[~foo.generally_submittable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tp_final), len(fp_final), len(fn_final), len(tn_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn_final.entropy < .04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn_final.reproducibility_test_v2.isin([\"pass\", \"borderline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn_final.passed_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn_final.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
